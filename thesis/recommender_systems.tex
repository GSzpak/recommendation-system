%
% Niniejszy plik stanowi przyk³ad formatowania pracy magisterskiej na
% Wydziale MIM UW.  Szkielet u¿ytych poleceñ mo¿na wykorzystywaæ do
% woli, np. formatujac wlasna prace.
%
% Zawartosc merytoryczna stanowi oryginalnosiagniecie
% naukowosciowe Marcina Wolinskiego.  Wszelkie prawa zastrze¿one.
%
% Copyright (c) 2001 by Marcin Woliñski <M.Wolinski@gust.org.pl>
% Poprawki spowodowane zmianami przepisów - Marcin Szczuka, 1.10.2004
% Poprawki spowodowane zmianami przepisow i ujednolicenie 
% - Seweryn Kar³owicz, 05.05.2006
% dodaj opcjê [licencjacka] dla pracy licencjackiej
\documentclass[licencjacka]{pracamgr}

\usepackage{polski}
\usepackage{amssymb}
%Jesli uzywasz kodowania polskich znakow ISO-8859-2 nastepna linia powinna byc 
%odkomentowana
\usepackage[latin2]{inputenc}
%Jesli uzywasz kodowania polskich znakow CP-1250 to ta linia powinna byc 
%odkomentowana
%\usepackage[cp1250]{inputenc}
\usepackage[linesnumbered]{algorithm2e}
\usepackage{caption}
\usepackage{afterpage}

\usepackage{amsmath}

\newcommand*\mean[1]{\bar{#1}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}

% Dane magistranta:

\author{Grzegorz Szpak}

\nralbumu{319400}

\title{Systemy rekomendacji bazuj±ce na metodzie wspólnej filtracji}

\tytulang{Recommender systems based on collaborative filtering}

%kierunek: Matematyka, Informatyka, ...
\kierunek{Matematyka}

% informatyka - nie okreslamy zakresu (opcja zakomentowana)
% matematyka - zakres moze pozostac nieokreslony,
% a jesli ma byc okreslony dla pracy mgr,
% to przyjmuje jedna z wartosci:
% {metod matematycznych w finansach}
% {metod matematycznych w ubezpieczeniach}
% {matematyki stosowanej}
% {nauczania matematyki}
% Dla pracy licencjackiej mamy natomiast
% mozliwosc wpisania takiej wartosci zakresu:
% {Jednoczesnych Studiow Ekonomiczno--Matematycznych}

% \zakres{Tu wpisac, jesli trzeba, jedna z opcji podanych wyzej}

% Praca wykonana pod kierunkiem:
% (podaæ tytu³/stopieñ imiê i nazwisko opiekuna
% Instytut
% ew. Wydzia³ ew. Uczelnia (je¿eli nie MIM UW))
\opiekun{prof. Andrzeja Skowrona / dr. Marcina Szczuki\\
  Instytut Matematyki / Instytut Informatyki\\
  }

% miesi±c i~rok:
\date{Lipiec 2016}

%Podaæ dziedzinê wg klasyfikacji Socrates-Erasmus:
\dziedzina{ 
%11.0 Matematyka, Informatyka:\\ 
11.1 Matematyka\\ 
%11.2 Statystyka\\ 
%11.3 Informatyka\\ 
%11.4 Sztuczna inteligencja\\ 
%11.5 Nauki aktuarialne\\
%11.9 Inne nauki matematyczne i informatyczne
}

%Klasyfikacja tematyczna wedlug AMS (matematyka) lub ACM (informatyka)
\klasyfikacja{68T05 Learning and adaptive systems}

% S³owa kluczowe:
\keywords{eksploracja danych, systemy rekomendacyjne, wspólna filtracja, algorytm k - najbli¿szych s±siadów}

% Tu jest dobre miejsce na Twoje w³asne makra i~¶rodowiska:
\newtheorem{defi}{Definicja}[section]

% koniec definicji

\begin{document}
\maketitle

%tu idzie streszczenie na strone poczatkowa
\begin{abstract}
  W pracy przedstawiono analizê systemów rekomendacyjnych opartych
  na metodzie wspólnej filtracji. Zaprezentowane zosta³y dwa podstawowe typy
  wspólnej filtracji - filtracja oparta o u¿ytkowników oraz filtracja oparta o
  przedmioty. Autor skupia siê na implementacji tej metody opartej na algorytmie
  k - najbli¿szych s±siadów. Przedstawione zostaj± ró¿ne warianty poszczególnych
  sk³adowych algorytmu (wybór funkcji podobieñstwa, rozmiar s±siedztwa, sposób ustalania
  oceny na podstawie ocen s±siadów) i ich wp³yw na jako¶æ systemu.
\end{abstract}

\tableofcontents
%\listoffigures
%\listoftables

\chapter{Wprowadzenie}
%\addcontentsline{toc}{chapter}{Wprowadzenie}
\section{Systemy rekomendacyjne i ich znaczenie}
Ka¿dego dnia stawiani jeste¶my przed szeregiem wyborów. Któr± ksi±¿kê przeczytaæ?
Jaki film obejrzeæ? Któr± stronê internetow± odwiedziæ? Jako ¿e ilo¶æ informacji w
otaczaj±cym nas ¶wiecie ro¶nie du¿o szybciej ni¿ nasze mo¿liwo¶ci poznawcze, konieczne sta³o siê stworzenie technologii, która bêdzie w stanie
wybraæ informacje najbardziej dla nas u¿yteczne. Tak± rolê we wspó³czesnych aplikacjach internetowych pe³ni± systemy rekomendacyjne. Bazuj±c na dotychczasowej aktywno¶ci u¿ytkownika, systemy rekomendacyjne staraj± siê 
przewidzieæ jego ocenê wobec danego przedmiotu. Terminy "ocena" i "przedmiot" s±
oczywi¶cie ogólne i w zale¿no¶ci od zastosowania mog± reprezentowaæ ró¿ne zjawiska - od wystawienia rzeczywistej oceny filmowi, przez kupno przedmiotu w sklepie internetowym, po fakt do³±czenia do grupy na portalu spo³eczno¶ciowym.

Przydatno¶æ systemów rekomendacyjnych obrazuje najlepiej tak zwany "fenomen d³ugiego ogona" (ang. \textit{long tail phenomenon}). + ile w google netflix
\section{Fenomen "d³ugiego ogona"}

\section{Typy systemów rekomendacyjnych}
W zale¿no¶ci od zastosowanych metod, systemy rekomendacyjne dzieli siê na 4 kategorie:
\begin{enumerate}
\item \textbf{Systemy bazuj±ce na wspólnej filtracji (ang. \textit{collaborative filtering, CF})}

    Podej¶cie wspólnej filtracji polega na wyznaczaniu preferencji danego u¿ytkownika
    bazuj±c na preferencjach u¿ytkowników o podobnym gu¶cie. Podobieñstwo to jest
    wyznaczane na podstawie wcze¶niejszych zachowañ u¿ytkownika. Ze wzglêdu na
    prostotê implementacji i wysok± jako¶æpredykcji, wspólne filtrowanie
    jest najbardziej popularn± i najczê¶ciej stosowan± technikê rekomendacji.
    Dodatkow± zalet± tej metody jest jej elastyczno¶æ i mo¿liwo¶æ stosowania w wielu
    dziedzinach - system oparty na wspólnej filtracji jest w stanie udzielaæ dok³adnych
    rekomendacji bez potrzeby "zrozumienia" samego przedmiotu. Niepotrzebne s±
    dodatkowe dane na temat u¿ytkowników czy przedmiotów - wystarczy
    sama historia ocen.
    
    Wady wspólnej filtracji s± natomiast nastêpuj±ce:
    \begin{itemize}
    \item wprowadzanie nowego u¿ytkownika lub przedmiotu do systemu (ang.
    \textit{cold start problem})
    \item ciê¿ko jest uzyskaæ sensowne rekomendacje dla u¿ytkownika o unikalnych 
    preferencjach
    \item rzadko¶æ danych - pojedynczy u¿ytkownik ocenia zwykle niewielki u³amek
    dostêpnych przedmiotów
    \item w niektórych wersjach \textit{collaborative filtering}
    problemem mo¿e byæ te¿ skalowalno¶æ.
    \end{itemize}
    
    W pozosta³ej czê¶ci pracy autor skupi siê na ró¿nych wariantach
    \textit{collaborative filtering} i spróbuje
    w oparciu o tê technikê zbudowaæ jak najbardziej wydajny system rekomendacji.

\item \textbf{Systemy oparte na zawarto¶ci (ang. \textit{content - based}))}

    To podej¶cie koncentruje siê na charakterystyce samych przedmiotów. Przedmiot
    reprezentowany jest przez zbiór cech. Cechami filmu
    mog± byæ na przyk³ad: gatunek, rok produkcji, obsada aktorska, re¿yser.
    Na podstawie warto¶ci atrybutów wyznaczane jest podobieñstwo miêdzy przedmiotami,
    nastêpnie u¿ytkownikowi prezentowane s± przedmioty podobne do dotychczas
    polubionych. Przyk³adowo, je¶li u¿ytkownik czêsto ogl±da³ filmy sensacyjne
    wyre¿yserowane przez Martina Scorsese, system bêdzie rekomendowa³ inne filmy
    tego re¿ysera.
    
    Metoda bazuj±ca na zawarto¶ci tak¿e jest szeroko stosowana. Do jej zalet zaliczyæ
    mo¿na:
    \begin{itemize}
        \item niski poziom skomplikowania
        \item w przeciwieñstwie do wspólnej filtracji, rekomendacja dla danego u¿ytkownika
        nie zale¿y od ocen innych u¿ytkowników
        \item transparentno¶æ - rekomendacje mog± byæ w ³atwy sposób wyt³umaczone
        na podstawie modelu (które cechy przedmiotu zadecydowa³y o jego wyborze)
        \item mo¿liwo¶æ rekomendacji przedmiotów nieocenionych jeszcze przez
        ¿adnego u¿ytkownika.
    \end{itemize}       
    
    Tego typu podej¶cie wymaga jednak czêsto wiedzy eksperckiej przy tworzeniu
    atrybutów przedmiotów. Z racji swojej natury, s³abo sprawdza siê te¿ przy
    rekomendacji przedmiotów o innej charakterystyce ni¿ dotychczas ocenione przez
    u¿ytkownika.

\item \textbf{Systemy bazuj±ce na osobowo¶ci}

    To stosunkowo nowe podej¶cie, zosta³o zaproponowane przez Ricardo Buettnera w [3].
    Polega na stworzeniu profilu osobowo¶ciowego u¿ytkownika na podstawie jego zachowañ
    w sieciach spo³eczno¶ciowych i prezentowaniu tre¶ci dopasowanych do tego profilu.

\item \textbf{Systemy hybrydowe}

    Polegaj± na ³±czeniu wy¿ej opisanych technik. Systemy hybrydowe mog± byæ
    implementowane w wielu wersjach: przez wykorzystanie wspólnej filtracji oraz
    rekomendacji opartej na zawarto¶ci osobno, a nastêpnie po³±czeniu wyników,
    przez wykorzystanie dodatkowej wiedzy o u¿ytkownikach czy przedmiotach
    w metodzie collaborative filtering czy przez zunifikowanie ró¿nych podej¶æ w jeden
    model. £±czenie ró¿nych podej¶æ mo¿e czêsto wyra¼nie podnie¶æ jako¶æ
    rekomendacji. Wad± tego typu systemów jest zwykle wysoki poziom skomplikowania.
\end{enumerate}

\section{The Netflix Prize}
Do znacznego rozwoju badañ nad systemami rekomendacyjnymi przyczyni³
siê konkurs The Netflix Prize, zorganizowany przez internetow± wypo¿yczalniê filmów Netflix\footnote{https://www.netflix.com} w 2006 roku. Konkurs polega³ na przewidywaniu ocen, jakie u¿ytkownicy wystawiliby filmom, na podstawie historycznych danych. 
Opublikowany zbiór treningowy zawiera³ 100,480,507 ocen wystawionych przez
480,189 u¿ytkowników 17,770 filmom. Aby otrzymaæ g³ówn± nagrodê - \$1,000,000 - 
nale¿a³o poprawiæ wynik algorytmu firmy Netflix (o nazwie Cinematch) o co najmniej 10\%.
Zawody zosta³y rozstrzygniête dopiero w roku 2009, kiedy algorytm zespo³u BellKor's Pragmatic Chaos poprawi³ wynik algorytmu Cinematch o 10.6\%. Zwyciêski
algorytm by³ algorytmem hybrydowym opartym miêdzy innymi na wspólnej filtracji,
rozk³adzie macierzy wed³ug warto¶ci osobliwych oraz wzmacnianych drzewach decyzyjnych (ang.
\textit{gradient boosted decision trees}).

\chapter{Formalizacja problemu rekomendacji}\label{r:definitions}
\section{Podstawowe pojêcia}
    Dwoma glównymi pojêciami wyorzystywanymi w systemach rekomendacyjnych s±
    \textit{U¿ytkownik} oraz \textit{przedmiot}. U¿ytkownicy maj± preferencje wobec
    niektórych przedmiotów, nazywane \textit{ocen±}.
    Preferencje s± czêsto reprezentowane jako zbiór trójek $(\textit{u¿ytkownik, przedmiot, ocena})$. Jak wspomniano wcze¶niej, to, czym dok³adnie jest \textit{ocena}, zale¿y od
    charakteru serwisu. Ocena mo¿e byæ liczb± ca³kowit± pochodz±c± z okre¶lonego
    przedzia³u (przyk³adowo: piêciopunktowa skala ocen w serwisie Netflix) lub mieæ
    postaæ binarn± (u¿ywane w serwisach spo³eczno¶ciowych "lubiê" / "nie lubiê").
    Unarne oceny, jak na przyk³ad informacja, czy u¿ytkownik kupi³ dany przedmiot,
    s± z kolei zwykle wykorzystywane w sklepach internetowych.
    
\section{Oznaczenia}    
    Niech $U = \{u_1,u_2,\cdots,u_k\}$ oznacza zbiór u¿ytkowników, $I = \{i_1,i_2,\cdots,i_l\}$ - zbiór przedmiotów, a $R= \{r_1,r_2,\cdots,r_m\}$ - zbiór ocen.
    
    \begin{defi}\label{macierz}
      Zbiór $S \subset U \times I \times R$ tworzy macierz o wymiarach $|U| \times |I|$,
      w której element $r$ o wspó³rzêdnych $(x, y)$ odpowiada trójce $(u_x, i_y, r)$.
      Taka macierz nazywana bêdzie \textbf{macierz± u¿yteczno¶ci} lub \textbf{macierz± ocen}.
    \end{defi}
    Przyk³ad macierzy u¿yteczno¶ci prezentuje tabela \ref{t:ratings_matrix}:

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Przyk³adowa macierz ocen}
\label{t:ratings_matrix}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
             & Matrix & Szklana Pu³apka & Titanic & Forrest Gump & Wall-E \\ \hline
U¿ytkownik A & 5      & 1               & ?       & 2            & 2      \\ \hline
U¿ytkownik B & 1      & 5               & 2       & 5            & 5      \\ \hline
U¿ytkownik C & 2      & ?               & 3       & 5            & 4      \\ \hline
U¿ytkownik D & 4      & 3               & 5       & 3            & ?      \\ \hline
\end{tabular}
\end{table}    
    \hfill \\
    Parom $(u, i)$, dla których u¿ytkownik $u$ nie oceni³ jeszcze przedmiotu $i$,
    odpowiadaj± puste pola w macierzy ocen. Te pola s± zaznaczone symbolem "?".
    
    
    Do ka¿dego u¿ytkownika $u$ przypisany jest zbiór
    $I_u \subseteq I$ ocenionych przez niego przedmiotów. Analogicznie, $U_i \subseteq U$
    oznaczaæ bêdzie zbiór u¿ytkowników, którzy ocenili przedmiot $i$. Niech dalej $M$
    reprezentuje macierz u¿yteczno¶ci, gdzie $r_{ui}$ jest ocen± udzielon±
    przedmiotowi $i$ przez u¿ytkownika $u$. Niech $r_u$ oznacza $|I|$ - wymiarowy
    wektor ocen u¿ytkownika $u$ (brak oceny reprezentowany jest przez $0$), 
    a $\mean{r}_u$ - ¶redni± z ocen wystawionych przez
    tego u¿ytkownika, tj. $\mean{r}_u = \frac{\sum_{i \in I_u} r_{ui}}{|I_u|}$.
    Podobnie $c_i$ reprezentowaæ bêdzie $|U|$ - wymiarowy wektor ocen wystawionych
    przedmiotowi $i$, za¶ $\mean{c}_i$ - jego ¶redni± notê.
    
\section{Formalna definicja problemu}
    Przy ocenie jako¶ci systemu rekomendacyjnego definiuje siê zwykle ([1], [2] TODO)
    dwa problemy:
    \begin{enumerate}
    \item Zadanie rekomendacji: maj±c danego u¿ytkownika $u$, wyznaczyæ $n$
    przedmiotów najbardziej pasuj±cych do gustu tego u¿ytkownika.

    \item Zadanie regresji - niech $S_{train} \subseteq U \times I \times R$ bêdzie
    zbiorem ocen dostêpnych w systemie, a $S_{test} \subseteq U \times I$ -
    zbiorem par $(\textit{u¿ytkownik, przedmiot})$, dla których preferencje chcemy okre¶liæ.
    Celem jest nauczenie funkcji $f: U \times I \rightarrow R$, która bêdzie
    minimalizowaæ pewn± funkcjê b³êdu $e: (U \times I \rightarrow R) \times (U \times I) \rightarrow \mathbb{R}$.
    
    Dwie najczê¶ciej u¿ywane funkcje straty to ¶redni bezwzglêdny b³±d
    (ang. \textit{Mean Absolute Error}, MAE):
    \begin{equation} \label{mae}
        MAE(f, S_{test}) = \frac{1}{S_{test}} \sum_{(u,i) \in S_{test}} |f(u,i) - r_{ui}|
    \end{equation}
    oraz pierwiastek b³êdu ¶redniokwadratowego
    (ang. \textit{Root Mean Squared Error}, RMSE):
    \begin{equation} \label{rmse}
        RMSE(f, S_{test}) = \sqrt{\frac{1}{S_{test}} \sum_{(u,i) \in S_{test}} (f(u,i) - r_{ui})^2}
    \end{equation}
    TODO normalized mean squared error
    \end{enumerate}
    Zalet± obydwu funkcji jest zachowanie skali, z której pochodz± oceny - przyk³adowo
    w piêciopunktowej skali, reprezentowanej przez liczby ca³kowite z przedzia³u
    $[1,5] $, MAE o warto¶ci $0.7$ oznacza, ¿e algorytm ¶rednio myli³
    siê o $0.7$ punktu.

\afterpage{\blankpage}


\chapter{Wspólna filtracja}\label{r:filtracja}    
    G³ówna idea, na której bazuje metoda \textit{collaborative filtering},
    polega na tym, ¿e ocena u¿ytkownika $u$ dla przedmiotu $i$ bêdzie podobna
    do oceny innego u¿ytkownika $v$, którego dotychczasowy schemat oceniania by³
    zbli¿ony do ocen $u$.
    Analogicznie, preferencje u¿ytkownika $u$ wobec przedmiotów $i$ oraz
    $j$ bêd± podobne, je¶li pozostali u¿ytkownicy oceniali oba przedmioty w
    analogiczny sposób.
    
    Algorytmy wspólnej filtracji mo¿na podzieliæ na dwa typy:
    \begin{itemize}
    \item wspólna filtracja oparta na modelu - systemy oparte na tym podej¶ciu
    wykorzystuj± dostêpne oceny w celu wyuczenia modelu, który nastêpnie
    bêdzie przewidywa³ nieznane warto¶ci $r_{ui}$. W tego typu metodzie u¿ywa siê
    na przyk³ad rozk³adu macierzy u¿yteczno¶ci wed³ug warto¶ci osobliwych,
    maszyn wektorów wspieraj±cych, sieci Bayesowskie (TODO: bibliografia) oraz
    algorytm Expectation - Maximisation.
    \item wspólna filtracja oparta na s±siedztwie - w tej metodzie ustala siê
    funkcjê podobieñstwa, a nastêpnie u¿ywa siê jej do wyznaczenia zbioru \textit{s±siadów} -
    u¿ytkowników b±d¼ przedmiotów charakteryzuj±cych siê podobnym schematem oceniania.
    Ostateczna ocena wyznaczana jest tylko na podstawie ocen s±siadów.
    \end{itemize}
        
    Szczegó³ow± analizê filtracji opartej na modelu mo¿na znale¼æ w TODO. W dalszej czê¶ci pracy
    autor skupi siê na podej¶ciu bazuj±cym na s±siedztwie.
    
    
\section{Filtracja w oparciu o u¿ytkowników}
    Podej¶cie bazuj±ce na u¿ytkownikach by³o pierwsz± zautomatyzowan±
    metod± wspólnej filtracji. Zosta³o wprowadzone pierwszy raz w ramach
   \textit{GroupLens Research Project}\footnote{Projekt badawczy prowadzony na Uniwersytecie Minnesota}
   [TODO bibliografia].
    
    Za³ó¿my, ¿e dana jest funkcja podobieñstwa $s_{users}: U \times U \rightarrow \mathbb{R}$.
    Schemat wyznaczania oceny u¿ytkownika $u$ dla przedmiotu $i$
    jest nastêpuj±cy (TODO rys 1.):
    \begin{algorithm}[ht]\label{alg}
    \LinesNumbered{
    \ForEach{$u' \in U \setminus \{u\}$}{
        Oblicz $s_{users}(u, u')$\;
    }        
    Wyznacz $N_i(u)$ - zbiór s±siadów, którzy ocenili $i$\; \label{alg:select}
    Wyznacz $r_{ui}$ na podstawie $\{r_{vi} \; | \; v \in N_i(u)\}1$\; \label{alg:result}
    }
    \end{algorithm}
    
    Najczê¶ciej spotykan± metod± wyznaczania zbioru s±siadów $N_i(u)$
    (linia \ref{alg:select})
    jest wybranie $k$ u¿ytkowników o najwiêkszej warto¶ci funkcji podobieñstwa,
    gdzie $k$ jest parametrem algorytmu. Podstawow± metod± wyznaczania oceny
    (linia \ref{alg:result}) jest z kolei wziêcie ¶redniej oceny ze zbioru s±siadów:
     \begin{equation} \label{result:mean}
        r_{ui} = \frac{1}{|N_i(u)|} \sum_{v \in N_i(u) r_{vi}} r_{vi}
    \end{equation}

\subsection{Wyznaczanie podobieñstwa miêdzy u¿ytkownikami} \label{subs:user_sim}

    Wybór odpowiedniej funkcji podobieñstwa $s_{users}$ jest najwa¿niejsz± czê¶ci± algorytmu
    wspólnej filtracji. Odgrywa ona podwójn± rolê:
    \begin{itemize}
    \item umo¿liwia wyznaczenie odpowiedniego zbioru $N_i(u)$
    \item w niektórych podej¶ciach warto¶ci funkcji $s_{users}$ pozwalaj± na dok³adniejsze
    wyznaczenie ostatecznego wyniku (wiêcej w rozdziale \ref{r:optimization})
    \end{itemize}
    Poni¿ej znajduje siê przegl±d funkcji podobieñstwa najczê¶ciej opisywanych w literaturze.
    
\subsubsection{Miary podobieñstwa bazuj±ce na korelacji}
 \subsubsection{Inne miary podobieñstwa}
    \begin{itemize}
    \item \textbf{Wspó³czynnik korelacji liniowej Pearsona}
    
    Wspó³czynnik Pearsona okre¶la poziom zale¿no¶ci liniowej miêdzy zmiennymi losowymi.
    Estymator wspó³czynnika korelacji liniowej dla wektorów prób losowych
    $x, y \in \mathbb{R}^n$ jest zdefiniowany nastêpuj±co:
    \begin{equation}
         pearson_{xy} = \frac{\sum_{i=1}^n(x_i - \mean{x})(y_i - \mean{y})}{\sqrt{\sum_{i=1}^n (x_i - \mean{x})^2}\sqrt{\sum_{i=1}^n (y_i - \mean{y})^2}},
    \end{equation}
    gdzie $\mean{x}$, $\mean{y}$ oznaczaj± warto¶ci ¶rednie z tych prób, tj
    $\mean{x} = \frac{\sum_{i=1}^n x_i}{n}$, $\mean{y} = \frac{\sum_{i=1}^n y_i}{n}$.
    Wspó³czynnik korelacji pearsona przyjmuje warto¶ci z przedzia³u $[-1,1]$. Warto¶ci
    bliskie $1$ oznaczaj± siln± zale¿no¶æ liniow± miêdzy $x$ a $y$, warto¶ci bliskie zera - 
    brak liniowej zale¿no¶ci, natomiast warto¶ci bliskie $-1$ - ujemn± liniow± zale¿no¶æ.
    
    W kontek¶cie systemów rekomendacyjnych, wspó³czynnik korelacji okre¶la siê jak poni¿ej:
    \begin{equation}
        pearson\_corr(u, v) = \frac{\sum_{i \in I_u \cap I_v}(r_{ui} - \mean{r}_u)(r_{vi} - \mean{r}_v)}{\sqrt{\sum_{i \in I_u \cap I_v}(r_{ui} - \mean{r}_u)^2}\sqrt{\sum_{i \in I_u \cap I_v}(r_{vi} - \mean{r}_v)}} \label{sim:pearson}
    \end{equation}
    Jest to najbardziej popularna funkcja do okre¶lania podobieñstwa miêdzy u¿ytkownikami.
    Wad± korelacji Pearsona jest zwracanie wysokiego podobieñstwa dla par u¿ytkowników,
    którzy ocenili niewielk± liczbê takich samych przedmiotów. Jednym z mo¿liwych
    sposobów obej¶cia tego problemu jest ustalenie progu $T$ i przeskalowanie
    wyniku, przyk³adowo przez pomno¿enie go przez $min(\frac{|I_u \cap I_v|}{T}, 1)$.
    
    \item \textbf{Zmodyfikowana korelacja Pearsona}
    
    Niektóre systemy interpretuj± medianê ze skali ocen $r_m$ jako neutralne nastawienie
    u¿ytkownika wobec przedmiotu. Ekstrand i in. zaproponowali w [3] (TODO bibliografia)
    modyfikacjê wspó³czynnika korelacji Pearsona, w której wektor ocen jest normalizowany
    przy u¿yciu owej mediany zamiast ¶redniej:
    \begin{equation}
        median\_centered\_corr(u, v) = \frac{\sum_{i \in I_u \cap I_v}(r_{ui} - r_m)(r_{vi} - r_m)}{\sqrt{\sum_{i \in I_u \cap I_v}(r_{ui} - r_m)^2}\sqrt{\sum_{i \in I_u \cap I_v}(r_{vi} - r_m)}}
    \end{equation}
   
    \item \textbf{Wspó³czynnik korelacji rang Spearmana}
    
    Podczas gdy wspó³czynnik Pearsona wykorzystuje bezpo¶rednie warto¶ci
    ocen $r_{ui}$ do wyznaczenia korelacji, metoda Spearmana polega na przyznaniu
    tym ocenom rang. Wektor ocen $r_u$ jest przekszta³cany w wektor rang w nastêpuj±cy
    sposób: najwy¿ej oceniony przedmiot otrzymuje rangê $1$, kolejne przedmioty
    otrzymuj± wy¿sze rangi. Przedmiotom z t± sam± ocen± przyznaje siê ¶redni± rangê
    dla ich pozycji. Oznaczaj±c przez $k_{ui}$ rangê przyznan± przedmiotowi $i$
    w kontek¶cie u¿ytkownika $u$, otrzymujemy wzór:
    \begin{equation}
        spearman\_rank\_corr(u, v) = \frac{\sum_{i \in I_u \cap I_v}(k_{ui} - \mean{k}_u)(k_{vi} - \mean{k}_v)}{\sqrt{\sum_{i \in I_u \cap I_v}(k_{ui} - \mean{k}_u)^2}\sqrt{\sum_{i \in I_u \cap I_v}(k_{vi} - \mean{k}_v)}}
    \end{equation}
        
    G³ówn± zalet± wspó³czynnika Spearmana jest unikniêcie problemu normalizacji
    ocen (wiêcej o normalizacji w rozdziale \ref{r:optimization}). Obliczanie rang wymaga
    jednak dodatkowego kosztu.
    \end{itemize}
    
\subsubsection{Inne miary podobieñstwa}
    \begin{itemize}
    \item \textbf{Podobieñstwo cosinusowe}
    
    Cosinus k±ta miêdzy wektorami $x$, $y$ w przestrzeni euklidesowej $(V, < \cdot >)$
    wyra¿a siê przez:
    \begin{equation}
        cos(x, y) = \frac{<x, y>}{\norm{x} \norm{y}}
    \end{equation}
    Dla wektorów z przestrzeni $\mathbb{R}^n$ ze standardowym iloczynem skalarnym,
    im wiêksza warto¶æ bezwzglêdna cosinusa, tym mniejszy k±t miêdzy nimi,
    co z kolei odpowiada intuicyjnie wiêkszemu "podobieñstwu" miêdzy wektorami.
    
    Ta intuicja le¿y u podstaw wykorzystania miary cosinusowe jako funkcji podobieñstwa,
    definuj±c j± jak poni¿ej:
    \begin{equation}
        cosine(u, v) = \frac{r_u \cdot r_v}{\norm{r_u}_2 \norm{r_v}_2} \label{sim:cosine}
    \end{equation}
    
    Wad± wydawaæ siê mo¿e reprezentowanie nieznanych ocen przez $0$, co czêsto
    upodabnia brak oceny do oceny negatywnej. Co wiêcej, u¿ywanie tej funkcji
    podobieñstwa nie bierze pod uwagê statystycznych ró¿nic miêdzy ocenami u¿ytkowników
    (ró¿nych ¶rednich czy wariancji ocen).
    Mimo wymienionych wad, podobieñstwo cosinusowe daje zaskakuj±co dobre wyniki w praktyce,
    co poka¿e rozdzia³ \ref{r:experiment}.
    
    \item \textbf{Podobieñstwo Jaccarda}
    
    Wspó³czynnik podobieñstwa Jaccarda (inaczej: \textit{indeks Jaccarda}) mierzy podobieñstwo miêdzy dwoma zbiorami i jest zdefiniowany jako iloraz mocy przeciêcia
    zbiorów i mocy sum tych zbiorów. W kontek¶cie systemów rekomendacji
    wylicza siê go zatem nastêpuj±co:
    \begin{equation}
        jaccard(u, v) = \frac{|I_u \cap I_v|}{|I_u \cup I_v|} \label{sim:jaccard}
    \end{equation}
    Jako ¿e indeks Jaccarda ignoruje warto¶ci ocen, jego oczywist± wad± jest fakt utraty
    informacji przy skalach ocen innych unarna.
        
    \item \textbf{Rozszerzone podobieñstwo Jaccarda}
    
    Jest to wersja podobieñstwa Jaccarda dla wektorów z $\mathbb{R}^n$:
    \begin{equation}
        extended\_jaccard(x, y) = \frac{x \cdot y}{\norm{x}_2^2 + \norm{y}_2^2 - x \cdot y},
    \end{equation}
    czyli u¿ywane jako miara podobieñstwa u¿ytkowników bêdzie mia³o postaæ:
    \begin{equation}
        extended\_jaccard(u, v) = \frac{r_u \cdot r_v}{\norm{r_u}_2^2 + \norm{r_v}_2^2 - r_u \cdot r_v}, \label{sim:ext_jaccard}
    \end{equation}
    
    \item \textbf{Podobieñstwo euklidesowe}
    
    Odleg³o¶æ euklidesowa miêdzy
    u¿ytkownikami okre¶lona jest w naturalny sposób przez:
    \begin{equation}
       d_2(u, v) = \sqrt{\sum_{i \in I_u \cap I_v} (r_{ui} - r_{vi})^2}.
    \end{equation}
    S± ró¿ne mo¿liwo¶ci przekszta³cenia tej miary odleg³o¶ci w funkcjê podobieñstwa
    (id±c± w $[0, 1]$, gdzie 1 oznacza najwiêksze podobieñstwo).
    Do najczê¶ciej u¿ywanych nale¿±:
    \begin{equation}
       euclidean1(u, v) = \frac{1}{1 + d_2(u, v)} \label{sim:euclidean1}
    \end{equation}
    oraz
    \begin{equation}
       euclidean2(u, v) = e^{-d_2(u, v)} \label{sim:euclidean2}
    \end{equation}
    TODO: przewaga drugiej
    Te miary mo¿e byæ uogólniona poprzez u¿ycie odleg³o¶ci Minkowskiego:
    \begin{equation}
       d_p(u, v) = \bigg(\sum_{i \in I_u \cap I_v} |r_{ui} - r_{vi}|^p \bigg)^{\frac{1}{p}}
    \end{equation}   
     
    \item \textbf{Ró¿nica ¶redniokwadratowa (ang. \textit{mean squared difference, MSD})}
    
    Podobn±, bazuj±c± na odleg³o¶ci miêdzy ocenami funkcj± podobieñstwa jest ró¿nica
    ¶redniokwadratowa. Definiuje siê j± jako odwrotno¶æ ¶redniego kwadratu ró¿nicy
    miêdzy ocenami u¿ytkowników $u$ i $v$:
    \begin{equation}
        MSD(u, v) = \frac{|I_u \cap I_v |}{\sum_{i \in I_u \cap I_v} (r_{ui} - r_{vi})^2}
    \end{equation}
    
    Ró¿nica ¶redniokwadratowa, podobnie jak podobieñstwo euklidesowe,
    nie odzwierciedla ujemnej korelacji miêdzy u¿ytkownikami. Posiadanie informacji
    o takiej korelacji mo¿e czasami zwiêkszyæ jako¶æ predykcji (TODO bibliografia).
    \end{itemize}

\section{Filtracja w oparciu o przedmioty}
    Obok wielu zalet, wspólna filtracja bazuj±ca na u¿ytkownikach ma jedn± powa¿n±
    wadê - brak skalowalno¶ci. Wyznaczanie zbioru $N_i(u)$ jest operacj± o z³o¿ono¶ci
    $\mathcal{O}(|U|)$ (lub gorszej - bezpo¶rednie wyliczanie warto¶ci funkcji podobieñstwa
    $s$ wymaga czasu $\mathcal{O}(|U||I|)$). W dobie serwisów maj±cych setki milionów
    u¿ytkowników potrzebne by³o bardziej skalowalne podej¶cie.
    
    Naturalnym pomys³em wydawa³o siê zastosowanie tej samej metody,
    zmodyfikowanej przez zast±pienie u¿ytkowników przedmiotami. Zamiast szukania
    podobieñstw miêdzy zachowaniami u¿ytkowników, do wyznaczania rekomendacji
    wykorzystywane s± podobieñstwa miêdzy schematami oceniania przedmiotów.
    Je¶li dwa przedmioty $i$ i $j$ cieszy³y siê podobn± opini± w¶ród
    u¿ytkowników, mo¿na uznaæ je za podobne i wykorzystaæ ocenê, jak± u¿ytkownik $u$
    wystawi³ przedmiotowi $i$ do predykcji oceny dla przedmiotu $j$.
    Warto zauwa¿yæ, ¿e ta wersja metody \textit{collaborative filtering} jest podobna
    do rekomendacji opartej na zawarto¶ci, z t± ró¿nic±, ¿e
    do wyznaczania podobieñstwa u¿ywa siê preferencji u¿ytkowników zamiast cech
    przedmiotów.
    
    Zamiast funkcji $s_{users}$ mamy zatem funkcjê
    $s_{items}: I \times I \rightarrow \mathbb{R}$, na której podstawie
    wyznaczamy zbiór $N_u(i)$ przedmiotów najbardziej podobnych do $i$
    ocenionych przez $u$. Porównanie z³o¿ono¶ci czasowej i obliczeniowej obu
    sposobów wspólnej filtracji przedstawia tabela \ref{t:complexities}.
\hfill \\  
\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Porównanie z³o¿ono¶ci pamiêciowej i obliczeniowej obu \\wersji wspólnej filtracji} \label{t:complexities}
\begin{tabular}{|l|l|l|l|}
\hline
            & Pamiêæ               & Czas uczenia            & Czas zapytania     \\ \hline
U¿ytkownicy & $\mathcal{O}(|U|^2)$ & $\mathcal{O}(|U|^2|I|)$ & $\mathcal{O}(|U|)$ \\ \hline
Przedmioty  & $\mathcal{O}(|I|^2)$ & $\mathcal{O}(|I|^2|U|)$ & $\mathcal{O}(|I|)$ \\ \hline
\end{tabular}
\end{table}

\hfill \\
Zak³adaj±c, ¿e $|U| \gg |I|$ (co jest prawd± w przypadku wiêkszo¶ci serwisów), ³atwo
zauwa¿yæ, ¿e "przedmiotowe" podej¶cie do wspólnej filtracji pozwala w znacz±cy sposób
zmniejszyæ z³o¿ono¶æ zarówno czasow±, jak i pamiêciow± algorytmu. Warto przy tym
zaznaczyæ, ¿e macierz u¿yteczno¶ci jest czêsto macierz± rzadk±, co znacznie przyspiesza
obliczanie warto¶ci funkcji podobieñstwa i co za tym idzie, czyni metodê wspólnej filtracji
opart± na s±siedztwie jeszcze bardziej skalowaln±.

\subsection{Wyznaczanie podobieñstwa miêdzy przedmiotami} \label{subs:item_sim}

Nietrudno zauwa¿yæ, ¿e wymienione w sekcji \ref{subs:user_sim} funkcje podobieñstwa
mog± byæ z powodzeniem uogólnione i zastosowane przy wyznaczaniu podobieñstwa miêdzy
przedmiotami. Przyk³adowo, wspó³czynnik korelacji liniowej Pearsona (równanie \ref{sim:pearson}) dla przedmiotów mo¿na
zdefiniowaæ jako:
\begin{equation}
  pearson\_corr(i, j) = \frac{\sum_{u \in U_i \cap U_j}(r_{ui} - \mean{c}_i)(r_{uj} - \mean{c}_j)}{\sqrt{\sum_{u \in U_i \cap U_j}(r_{ui} - \mean{c}_i)^2}\sqrt{\sum_{u \in U_i \cap U_v}(r_{uj} - \mean{c}_j)}}
\end{equation}
Analogicznie zdefiniowaæ mo¿na pozosta³e miary.

Miarê podobieñstwa przeznaczon± specjalnie dla przedmiotów
zaproponowali Sarwar i in. w [4]. (TODO bibliografia) Bazuje ona na obserwacji,
i¿ ró¿nice w skalach ocen poszczególnych u¿ytkowników czêsto s± znacznie
wyra¼niejsze ni¿ w przypadku przedmiotów. Dlatego przy obliczaniu podobieñstwa
miêdzy przedmiotami wiêkszy sens mo¿e mieæ normalizacja oceny wzglêdem ¶redniej
oceny \textit{u¿ytkownika} zamiast \textit{przedmiotu}. Formalnie ta miara, zwana
\textbf{dopasowanym podobieñstwem cosinusowym (ang. \textit{Adjusted Cosine Similarity})} okre¶lona jest jako:
\begin{equation}
adjusted\_cosine(i, j) = \frac{\sum_{u \in U_i \cap U_j}(r_{ui} - \mean{r}_u)(r_{uj} - \mean{r}_u)}{\sqrt{\sum_{u \in U_i \cap U_j}(r_{ui} - \mean{r}_u)^2}\sqrt{\sum_{u \in U_i \cap U_v}(r_{uj} - \mean{r}_u)}} \label{sim:adjusted_cos}
\end{equation}

W niektórych przypadkach tak okre¶lona funkcja podobieñstwa daje lepsze wyniki ni¿
zwykle u¿ywane miary (TODO bibliografia).

\afterpage{\blankpage}

\chapter{Wp³yw miary podobieñstwa na jako¶æ predykcji} \label{r:experiment}

W poni¿szym rozdziale przedstawione zostan± wyniki eksperymentu, maj±cego na celu
ukazanie, jak wybór metody wspólnej filtracji oraz funkcji podobieñstwa wp³ywa
na jako¶æ systemu rekomendacji.

\section{Opis eksperymentu} \label{s:experiment}
\subsection{Opis zbioru danych}

W pracy wykorzystany zosta³ zbiór ocen filmów MovieLens\footnote{https://movielens.org/}. Zbiór sk³ada siê ze 100,000 ocen udzielonych 1682 filmom przez 943
u¿ytkowników, przy czym ka¿dy u¿ytkownik oceni³ co najmniej 20 filmów.
Skala ocen jest piêciopunktowa. Obok samych ocen, zbiór zawiera³ podstawowe informacje na temat filmów (m.in. tytu³, gatunek, datê wydania) oraz u¿ytkowników (wiek, p³eæ, zawód,
kod pocztowy). Dane zbierane
by³y w ramach wspomnianego wcze¶niej projektu GroupLens przez 7 miesiêcy.

\subsection{Sposób przeprowadzenia eksperymentu}

Jako¶æ predykcji sprawdzana by³a przy u¿yciu piêciowarstwowej walidacji krzy¿owej.
Zbiór ocen by³ podzielony na 5 równolicznych, roz³±cznych podzbiorów - skorzystano 
z gotowego podzia³u dostarczonego razem ze zbiorem danych przez zespó³ GroupLens.
Nastêpnie kolejno ka¿dy z podzbiorów s³u¿y³ jako zbiór testowy, a cztery pozosta³e
podzbiory tworzy³y zbiór treningowy. Ostateczny wynik jest ¶redni± z wyników piêciu
przeprowadzonych analiz.

Do oceny jako¶ci predykcji u¿yto funkcji straty opisanych w rozdziale \ref{r:definitions} -
MAE oraz RMSE.

Zbiór s±siadów wyznaczany by³ przez wziêcie 10 najbardziej podobnych u¿ytkowników b±d¼
przedmiotów. Ostateczna ocena wyliczana by³a jako ¶rednia z ocen s±siadów (zgodnie ze wzorem \ref{result:mean}).

Aby uzyskaæ punkt odniesienia, dla obydwu podej¶æ zosta³ równie¿ dodany wynik
predyktora bazowego (\textit{baseline}) - w przypadku u¿ytkowników zwraca³ on ¶redni±
ocenê dla danego u¿ytkownika ($r_{ui} = \mean{r}_u$), a w przypadku przedmiotów -
¶redni± ocenê wystawion± przedmiotowi ($r_{ui} = \mean{c}_i$).

\section{Wyniki}
Wyniki dla metody bazuj±cej na u¿ytkownikach w zale¿no¶ci od postaci funkcji podobieñstwa $s_{users}$ prezentuje tabela
\ref{t:exp_users}.

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Wyniki dla podej¶cia opartego na u¿ytkownikach}
\label{t:exp_users}
\begin{tabular}{|c|c|c|}
\hline
                         & MAE & RMSE \\ \hline
\textbf{$baseline$}      & \textbf{0.828} & \textbf{1.031} \\ \hline
$pearson\_corr$          & 5   & 1    \\ \hline
$median\_centered\_corr$ & 1   & 5    \\ \hline
$spearman\_rank\_corr$   & 2   & ?    \\ \hline
$cosine$                 & 4   & 3    \\ \hline
$jaccard$                &     &      \\ \hline
$extended\_jaccard$      &     &      \\ \hline
$euclidean1$             &     &      \\ \hline
$euclidean2$             &     &      \\ \hline
$MSD$                    &     &      \\ \hline
\end{tabular}
\end{table}

\hfill \\
Wyniki dla metody bazuj±cej na przedmiotach w zale¿no¶ci od postaci funkcji podobieñstwa $s_{items}$ prezentuje tabela
\ref{t:exp_items}.

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Wyniki dla podej¶cia opartego na przedmiotach}
\label{t:exp_items}
\begin{tabular}{|c|c|c|}
\hline
                         & MAE & RMSE \\ \hline
\textbf{$baseline$}      & \textbf{0.803} & \textbf{1.000} \\ \hline
$pearson\_corr$          & 5   & 1    \\ \hline
$median\_centered\_corr$ & 1   & 5    \\ \hline
$spearman\_rank\_corr$   & 2   & ?    \\ \hline
$cosine$                 & 4   & 3    \\ \hline
$jaccard$                &     &      \\ \hline
$extended\_jaccard$      &     &      \\ \hline
$euclidean1$             &     &      \\ \hline
$euclidean2$             &     &      \\ \hline
$MSD$                    &     &      \\ \hline
$adjusted\_cosine$       &     &      \\ \hline
\end{tabular}
\end{table}

\section{Wnioski}

\afterpage{\blankpage}

\chapter{Optymalizacja algorytmu opartego na s±siedztwie}\label{r:optimization}

W poni¿szym rozdziale przeanalizowane zostan± szczegó³y algorytmu najbli¿szych s±siadów - 
wybór zbioru s±siadów oraz wyliczanie wyniku na ich podstawie. Zaprezentowane zostan±
wyniki dalszych eksperymentów pokazuj±cych, jak obydwa aspekty wp³ywaj± na jako¶æ
predykcji.

\section{Wybór zbioru s±siadów}
Rozmiar zbioru $N$ najbli¿szych s±siadów oraz sposób tworzenia tego zbioru
na podstawie funkcji podobieñstwa mog± mieæ znaczny wp³yw na jako¶æ
systemu rekomendacji. Przy wiêkszej liczbie u¿ytkowników niemo¿liwe staje siê jednak
trzymanie ca³ej macierzy podobieñstwa w pamiêci. Równie¿ z powodu zbyt wysokiej 
z³o¿ono¶ci czasowej przegl±danie ca³ego zbioru $U$ lub $I$ przy ka¿dym zapytaniu
by³oby nieakcpetowalne. Z tego powodu wyznaczanie zbioru $N$
jest czêsto podzielone na dwa etapy: etap preprocessingu, w którym dla ka¿dego u¿ytkownika b±d¼ przedmiotu wylicza siê zbiór kandydatów na s±siadów, oraz etap
w³a¶ciwego wyboru s±siedztwa.

\subsection{Etap preprocessingu}

W tym etapie dla ka¿dego u¿ytkownika $u$ lub przedmiotu $i$ wyznaczany jest podzbiór
$U' \subset U$ (odpowiednio: $I' \subset I|$), przy czym $|U'| \ll |U|$, który, trzymany
w pamiêci podrêcznej, bêdzie pó¼niej s³u¿y³ do wyznaczania zbioru s±siadów. Warto przy tym tak dobraæ rozmiar zbioru $U'$, aby dla mo¿liwie du¿ej liczby zapytañ o ocenê $r_{uj}$
rozmiar zbioru $U' \setminus U_j$ przekracza³ oczekiwany rozmiar $N$.
Do najbardziej popularnych metod preprocessingu nale¿±:
\begin{itemize}
\item wybór $k'$ s±siadów z najwiêksz± warto¶ci± funkcji podobieñstwa
\item wybór s±siadów, dla których warto¶æ funkcji podobieñstwa przekracza pewien
ustalony próg $T$
\item je¶li u¿ywana jest funkcja podobieñstwa bazuj±ca na korelacji (wiêcej w sekcji \ref{subs:user_sim}), mo¿liwe jest odfiltrowanie s±siadów z ujemn± korelacj±
wzglêdem ocen danego u¿ytkownika b±d¼ przedmiotu.
\end{itemize}


\section{Wyznaczanie oceny na podstawie ocen s±siadów}


\chapter{Podsumowanie}

\section{Perspektywy wykorzystania w~przemy¶le}

Ze wzglêdu na znaczenie strategiczne wyników pracy ten punkt uleg³
utajnieniu.

\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}

\bibitem[Bea65]{beaman} Juliusz Beaman, \textit{Morbidity of the Jolly
    function}, Mathematica Absurdica, 117 (1965) 338--9.

\bibitem[Blar16]{eb1} Elizjusz Blarbarucki, \textit{O pewnych
    aspektach pewnych aspektów}, Astrolog Polski, Zeszyt 16, Warszawa
  1916.

\end{thebibliography}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: latin-2
%%% End:
