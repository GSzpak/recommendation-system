%
% Niniejszy plik stanowi przyk³ad formatowania pracy magisterskiej na
% Wydziale MIM UW.  Szkielet u¿ytych poleceñ mo¿na wykorzystywaæ do
% woli, np. formatujac wlasna prace.
%
% Zawartosc merytoryczna stanowi oryginalnosiagniecie
% naukowosciowe Marcina Wolinskiego.  Wszelkie prawa zastrze¿one.
%
% Copyright (c) 2001 by Marcin Woliñski <M.Wolinski@gust.org.pl>
% Poprawki spowodowane zmianami przepisów - Marcin Szczuka, 1.10.2004
% Poprawki spowodowane zmianami przepisow i ujednolicenie 
% - Seweryn Kar³owicz, 05.05.2006
% dodaj opcjê [licencjacka] dla pracy licencjackiej
\documentclass[licencjacka]{pracamgr}

\usepackage{polski}
\usepackage{amssymb}
%Jesli uzywasz kodowania polskich znakow ISO-8859-2 nastepna linia powinna byc 
%odkomentowana
\usepackage[latin2]{inputenc}
%Jesli uzywasz kodowania polskich znakow CP-1250 to ta linia powinna byc 
%odkomentowana
%\usepackage[cp1250]{inputenc}
\usepackage[linesnumbered]{algorithm2e}
\usepackage{caption}
\usepackage{afterpage}
\usepackage{graphicx}
\usepackage{amsmath}

\newcommand*\mean[1]{\bar{#1}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}
\def \hfillx {\hspace*{-\textwidth} \hfill}

% Dane magistranta:

\author{Grzegorz Szpak}

\nralbumu{319400}

\title{Systemy rekomendacji bazuj±ce na metodzie wspólnej filtracji}

\tytulang{Recommender systems based on collaborative filtering}

%kierunek: Matematyka, Informatyka, ...
\kierunek{Matematyka}

% informatyka - nie okreslamy zakresu (opcja zakomentowana)
% matematyka - zakres moze pozostac nieokreslony,
% a jesli ma byc okreslony dla pracy mgr,
% to przyjmuje jedna z wartosci:
% {metod matematycznych w finansach}
% {metod matematycznych w ubezpieczeniach}
% {matematyki stosowanej}
% {nauczania matematyki}
% Dla pracy licencjackiej mamy natomiast
% mozliwosc wpisania takiej wartosci zakresu:
% {Jednoczesnych Studiow Ekonomiczno--Matematycznych}

% \zakres{Tu wpisac, jesli trzeba, jedna z opcji podanych wyzej}

% Praca wykonana pod kierunkiem:
% (podaæ tytu³/stopieñ imiê i nazwisko opiekuna
% Instytut
% ew. Wydzia³ ew. Uczelnia (je¿eli nie MIM UW))
\opiekun{dr. Marcina Szczuki\\
  Instytut Informatyki\\
  }

% miesi±c i~rok:
\date{Lipiec 2016}

%Podaæ dziedzinê wg klasyfikacji Socrates-Erasmus:
\dziedzina{ 
%11.0 Matematyka, Informatyka:\\ 
11.1 Matematyka\\ 
%11.2 Statystyka\\ 
%11.3 Informatyka\\ 
%11.4 Sztuczna inteligencja\\ 
%11.5 Nauki aktuarialne\\
%11.9 Inne nauki matematyczne i informatyczne
}

%Klasyfikacja tematyczna wedlug AMS (matematyka) lub ACM (informatyka)
\klasyfikacja{68T05 Learning and adaptive systems}

% S³owa kluczowe:
\keywords{eksploracja danych, systemy rekomendacyjne, wspólna filtracja, algorytm k - najbli¿szych s±siadów}

% Tu jest dobre miejsce na Twoje w³asne makra i~¶rodowiska:
\newtheorem{defi}{Definicja}[section]

% koniec definicji

\begin{document}
\maketitle

%tu idzie streszczenie na strone poczatkowa
\begin{abstract}
  W pracy przedstawiono analizê systemów rekomendacyjnych opartych
  na metodzie wspólnej filtracji. Zaprezentowane zosta³y dwa podstawowe typy
  wspólnej filtracji - filtracja oparta o u¿ytkowników oraz filtracja oparta o
  przedmioty. Autor skupia siê na implementacji tej metody opartej na algorytmie
  k - najbli¿szych s±siadów. Przedstawione zostaj± ró¿ne warianty poszczególnych
  sk³adowych algorytmu (wybór funkcji podobieñstwa, rozmiar s±siedztwa, sposób ustalania
  oceny na podstawie ocen s±siadów) i ich wp³yw na jako¶æ systemu.
\end{abstract}

\tableofcontents
%\listoffigures
%\listoftables

\chapter{Wprowadzenie}
%\addcontentsline{toc}{chapter}{Wprowadzenie}
\section{Systemy rekomendacyjne i ich znaczenie}
Ka¿dego dnia stawiani jeste¶my przed szeregiem wyborów. Któr± ksi±¿kê przeczytaæ?
Jaki film obejrzeæ? Któr± stronê internetow± odwiedziæ? Jako ¿e ilo¶æ informacji w
otaczaj±cym nas ¶wiecie ro¶nie du¿o szybciej ni¿ nasze mo¿liwo¶ci poznawcze, konieczne sta³o siê stworzenie technologii, która bêdzie w stanie
wybraæ informacje najbardziej dla nas u¿yteczne. Tak± rolê we wspó³czesnych aplikacjach pe³ni± systemy rekomendacyjne. Bazuj±c na dotychczasowej aktywno¶ci u¿ytkownika, systemy rekomendacyjne staraj± siê 
przewidzieæ jego ocenê wobec danego przedmiotu. Terminy "ocena" i "przedmiot" s±
oczywi¶cie ogólne i w zale¿no¶ci od zastosowania mog± reprezentowaæ ró¿ne zjawiska - od wystawienia rzeczywistej oceny filmowi, przez kupno przedmiotu w sklepie internetowym, po fakt do³±czenia do grupy na portalu spo³eczno¶ciowym.

Stosowanie systemów rekomendacji przynosi korzy¶ci zarówno dla klienta, jak i dla
sprzedawcy (w³a¶ciciela serwisu). U¿ytkownik od razu otrzymuje tre¶æ, któr± jest zainteresowany - bez konieczno¶ci przegl±dania serwisu. Korzy¶ci sprzedawcy z kolei
mo¿na by mno¿yæ: od lepszego zrozumienia potrzeb u¿ytkownika, przez
zwiêkszon± ró¿norodno¶æ sprzedawanych produktów, po wzrost lojalno¶ci klientów - 
wszystko to przek³ada siê na pomno¿enie zysków. Z tego powodu systemy
rekomendacji stosowane s± przez najwiêksze firmy (¼ród³o: \cite{celma}):
\begin{itemize}
\item Netflix\footnote{https://www.netflix.com} - 2/3 ogl±danych filmów w wyniku rekomendacji
\item Google News\footnote{https://news.google.com} - rekomendacje generujê 38\% wiêcej ruchu
\item Amazon\footnote{https://www.amazon.com} - 35\% sprzeda¿y pochodz±cych z rekomendacji.
\end{itemize}

\section{Typy systemów rekomendacyjnych}
W zale¿no¶ci od zastosowanych metod, systemy rekomendacyjne dzieli siê na 4 kategorie:
\begin{enumerate}
\item \textbf{Systemy bazuj±ce na wspólnej filtracji (ang. \textit{collaborative filtering, CF})}

    Podej¶cie wspólnej filtracji polega na wyznaczaniu preferencji danego u¿ytkownika
    bazuj±c na preferencjach u¿ytkowników o podobnym gu¶cie. Podobieñstwo to jest
    wyznaczane na podstawie wcze¶niejszych zachowañ u¿ytkownika. Ze wzglêdu na
    prostotê implementacji i wysok± jako¶æ predykcji, wspólne filtrowanie
    jest najbardziej popularn± i najczê¶ciej stosowan± technikê rekomendacji.
    Dodatkow± zalet± tej metody jest jej elastyczno¶æ i mo¿liwo¶æ stosowania w wielu
    dziedzinach - system oparty na wspólnej filtracji jest w stanie udzielaæ dok³adnych
    rekomendacji bez potrzeby "zrozumienia" samego przedmiotu. Niepotrzebne s±
    dodatkowe dane na temat u¿ytkowników czy przedmiotów - wystarczy
    sama historia ocen.
    
    Wady wspólnej filtracji s± natomiast nastêpuj±ce:
    \begin{itemize}
    \item k³opotliwe wprowadzanie nowego u¿ytkownika lub przedmiotu do systemu (ang.
    \textit{cold start problem})
    \item ciê¿ko jest uzyskaæ sensowne rekomendacje dla u¿ytkownika o unikalnych 
    preferencjach
    \item rzadko¶æ danych - pojedynczy u¿ytkownik ocenia zwykle niewielki u³amek
    dostêpnych przedmiotów
    \item w niektórych wersjach \textit{collaborative filtering}
    problemem mo¿e byæ te¿ skalowalno¶æ.
    \end{itemize}
    
    W pozosta³ej czê¶ci pracy autor skupi siê na ró¿nych wariantach
    \textit{collaborative filtering} i spróbuje
    w oparciu o tê technikê zbudowaæ jak najbardziej wydajny system rekomendacji.

\item \textbf{Systemy oparte na zawarto¶ci (ang. \textit{content - based}))}

    To podej¶cie koncentruje siê na charakterystyce samych przedmiotów. Przedmiot
    reprezentowany jest przez zbiór cech. Cechami filmu
    mog± byæ na przyk³ad: gatunek, rok produkcji, obsada aktorska, re¿yser.
    Na podstawie warto¶ci atrybutów wyznaczane jest podobieñstwo miêdzy przedmiotami,
    nastêpnie u¿ytkownikowi prezentowane s± przedmioty podobne do dotychczas
    polubionych. Przyk³adowo, je¶li u¿ytkownik czêsto ogl±da³ filmy
    wyre¿yserowane przez Martina Scorsese, system bêdzie rekomendowa³ inne filmy
    tego re¿ysera.
    
    Metoda bazuj±ca na zawarto¶ci tak¿e jest szeroko stosowana. Do jej zalet zaliczyæ
    mo¿na:
    \begin{itemize}
        \item niski poziom skomplikowania
        \item w przeciwieñstwie do wspólnej filtracji, rekomendacja dla danego u¿ytkownika
        nie zale¿y od ocen innych u¿ytkowników
        \item transparentno¶æ - rekomendacje mog± byæ w ³atwy sposób wyt³umaczone
        na podstawie modelu (które cechy przedmiotu zadecydowa³y o jego wyborze)
        \item mo¿liwo¶æ rekomendacji przedmiotów nieocenionych jeszcze przez
        ¿adnego u¿ytkownika.
    \end{itemize}       
    
    Tego typu podej¶cie wymaga jednak czêsto wiedzy eksperckiej przy tworzeniu
    atrybutów przedmiotów. Z racji swojej natury, s³abo sprawdza siê te¿ przy
    rekomendacji przedmiotów o innej charakterystyce ni¿ dotychczas ocenione przez
    u¿ytkownika.

\item \textbf{Systemy bazuj±ce na osobowo¶ci}

    To stosunkowo nowe podej¶cie, zosta³o zaproponowane przez Ricardo Buettnera w \cite{buettner}.
    Polega na stworzeniu profilu osobowo¶ciowego u¿ytkownika na podstawie jego zachowañ
    w sieciach spo³eczno¶ciowych i prezentowaniu tre¶ci dopasowanych do tego profilu.

\item \textbf{Systemy hybrydowe}

    Polegaj± na ³±czeniu wy¿ej opisanych technik. Systemy hybrydowe mog± byæ
    implementowane w wielu wersjach: przez wykorzystanie wspólnej filtracji oraz
    rekomendacji opartej na zawarto¶ci osobno, a nastêpnie po³±czeniu wyników,
    przez wykorzystanie dodatkowej wiedzy o u¿ytkownikach czy przedmiotach
    w metodzie collaborative filtering czy przez zunifikowanie ró¿nych podej¶æ w jeden
    model. £±czenie ró¿nych podej¶æ mo¿e czêsto wyra¼nie podnie¶æ jako¶æ
    rekomendacji. Wad± tego typu systemów jest zwykle wysoki poziom skomplikowania.
\end{enumerate}

\section{The Netflix Prize}
Do znacznego rozwoju badañ nad systemami rekomendacyjnymi przyczyni³
siê konkurs The Netflix Prize, zorganizowany przez internetow± wypo¿yczalniê filmów Netflix w 2006 roku. Konkurs polega³ na przewidywaniu ocen, jakie u¿ytkownicy wystawiliby filmom, na podstawie historycznych danych. 
Opublikowany zbiór treningowy zawiera³ 100,480,507 ocen wystawionych przez
480,189 u¿ytkowników 17,770 filmom. Aby otrzymaæ g³ówn± nagrodê - \$1,000,000 - 
nale¿a³o poprawiæ wynik algorytmu firmy Netflix (o nazwie Cinematch) o co najmniej 10\%.
Zawody zosta³y rozstrzygniête dopiero w roku 2009, kiedy algorytm zespo³u BellKor's Pragmatic Chaos poprawi³ wynik algorytmu Cinematch o 10.6\%. Zwyciêski
algorytm by³ algorytmem hybrydowym opartym miêdzy innymi na wspólnej filtracji,
rozk³adzie macierzy wed³ug warto¶ci osobliwych oraz wzmacnianych drzewach decyzyjnych (ang. \textit{gradient boosted decision trees}).

\chapter{Formalizacja problemu rekomendacji}\label{r:definitions}
\section{Podstawowe pojêcia}
    Dwoma glównymi pojêciami wyorzystywanymi w systemach rekomendacyjnych s±
    \textit{U¿ytkownik} oraz \textit{przedmiot}. U¿ytkownicy maj± preferencje wobec
    niektórych przedmiotów, nazywane \textit{ocen±}.
    Preferencje s± czêsto reprezentowane jako zbiór trójek $(\textit{u¿ytkownik, przedmiot, ocena})$. Jak wspomniano wcze¶niej, to, czym dok³adnie jest \textit{ocena}, zale¿y od
    charakteru serwisu. Ocena mo¿e byæ liczb± ca³kowit± pochodz±c± z okre¶lonego
    przedzia³u (przyk³adowo: piêciopunktowa skala ocen w serwisie Netflix) lub mieæ
    postaæ binarn± (u¿ywane w serwisach spo³eczno¶ciowych "lubiê" / "nie lubiê").
    Unarne oceny, jak na przyk³ad informacja, czy u¿ytkownik kupi³ dany przedmiot,
    s± z kolei zwykle wykorzystywane w sklepach internetowych.
    
\section{Oznaczenia}    
    Niech $U = \{u_1,u_2,\cdots,u_k\}$ oznacza zbiór u¿ytkowników, $I = \{i_1,i_2,\cdots,i_l\}$ - zbiór przedmiotów, a $R= \{r_1,r_2,\cdots,r_m\}$ - 
    uporz±dkowany zbiór ocen, gdzie $r_1 < r_2 < \cdots < r_m$. Niech dalej $r_{med}$
    oznacza medianê zbioru $R$, czyli
    \begin{equation}
        r_{med} = r_{\frac{m+1}{2}}
    \end{equation}
    dla $m$ nieparzystego
    oraz
    \begin{equation}
        r_{med} = \frac{r_{\frac{m}{2}} + r_{\frac{m}{2} + 1}}{2}
    \end{equation}
    dla $m$ parzystego.
    
    \begin{defi}\label{macierz}
      Zbiór $S \subset U \times I \times R$ tworzy macierz o wymiarach $|U| \times |I|$,
      w której element $r$ o wspó³rzêdnych $(x, y)$ odpowiada trójce $(u_x, i_y, r)$.
      Taka macierz nazywana bêdzie \textbf{macierz± u¿yteczno¶ci} lub \textbf{macierz± ocen}.
    \end{defi}
    Przyk³ad macierzy u¿yteczno¶ci prezentuje tabela \ref{t:ratings_matrix}.

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Przyk³adowa macierz ocen}
\label{t:ratings_matrix}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
             & Matrix & Szklana Pu³apka & Titanic & Forrest Gump & Wall-E \\ \hline
U¿ytkownik A & 5      & 1               & ?       & 2            & 2      \\ \hline
U¿ytkownik B & 1      & 5               & 2       & 5            & 5      \\ \hline
U¿ytkownik C & 2      & ?               & 3       & 5            & 4      \\ \hline
U¿ytkownik D & 4      & 3               & 5       & 3            & ?      \\ \hline
\end{tabular}
\end{table}    
    \hfill \\
    Parom $(u, i)$, dla których u¿ytkownik $u$ nie oceni³ jeszcze przedmiotu $i$,
    odpowiadaj± puste pola w macierzy ocen. Te pola s± zaznaczone symbolem "?".
    
    
    Do ka¿dego u¿ytkownika $u$ przypisany jest zbiór
    $I_u \subseteq I$ ocenionych przez niego przedmiotów. Analogicznie, $U_i \subseteq U$
    oznaczaæ bêdzie zbiór u¿ytkowników, którzy ocenili przedmiot $i$. Niech dalej $M$
    reprezentuje macierz u¿yteczno¶ci, gdzie $r_{ui}$ jest ocen± udzielon±
    przedmiotowi $i$ przez u¿ytkownika $u$. Niech $r_u$ oznacza $|I|$ - wymiarowy
    wektor ocen u¿ytkownika $u$ (brak oceny reprezentowany jest przez $0$), 
    a $\mean{r}_u$ - ¶redni± z ocen wystawionych przez
    tego u¿ytkownika, tj.
    \begin{equation}
        \mean{r}_u = \frac{\sum_{i \in I_u} r_{ui}}{|I_u|}.
    \end{equation}
    Podobnie $c_i$ reprezentowaæ bêdzie $|U|$ - wymiarowy wektor ocen wystawionych
    przedmiotowi $i$, za¶ $\mean{c}_i$ - jego ¶redni± notê.
    
\section{Formalna definicja problemu}
    Przy ocenie jako¶ci systemu rekomendacyjnego definiuje siê zwykle (za \cite{ricci,ekstr})
    dwa problemy:
    \begin{enumerate}
    \item Zadanie rekomendacji - maj±c danego u¿ytkownika $u$, wyznaczyæ $n$
    przedmiotów najbardziej pasuj±cych do gustu tego u¿ytkownika.

    \item Zadanie regresji - niech $S_{train} \subseteq U \times I \times R$ bêdzie
    zbiorem ocen dostêpnych w systemie, a $S_{test} \subseteq U \times I$ -
    zbiorem par $(\textit{u¿ytkownik, przedmiot})$, dla których preferencje chcemy okre¶liæ.
    Celem jest nauczenie funkcji $f: U \times I \rightarrow R$, która bêdzie
    minimalizowaæ pewn± funkcjê b³êdu $e: (U \times I \rightarrow R) \times (U \times I) \rightarrow \mathbb{R}$.
    
    Dwie najczê¶ciej u¿ywane funkcje straty to ¶redni bezwzglêdny b³±d
    (ang. \textit{Mean Absolute Error}, MAE):
    \begin{equation} \label{mae}
        MAE(f, S_{test}) = \frac{1}{S_{test}} \sum_{(u,i) \in S_{test}} |f(u,i) - r_{ui}|
    \end{equation}
    oraz pierwiastek b³êdu ¶redniokwadratowego
    (ang. \textit{Root Mean Squared Error}, RMSE):
    \begin{equation} \label{rmse}
        RMSE(f, S_{test}) = \sqrt{\frac{1}{S_{test}} \sum_{(u,i) \in S_{test}} (f(u,i) - r_{ui})^2}
    \end{equation}
    \end{enumerate}
    Zalet± obydwu funkcji jest zachowanie skali, z której pochodz± oceny - przyk³adowo
    w piêciopunktowej skali, reprezentowanej przez liczby ca³kowite z przedzia³u
    $[1,5] $, MAE o warto¶ci $0.7$ oznacza, ¿e algorytm ¶rednio myli³
    siê o $0.7$ punktu.

\afterpage{\blankpage}


\chapter{Wspólna filtracja}\label{r:filtracja}    
    G³ówna idea, na której bazuje metoda \textit{collaborative filtering},
    polega na tym, ¿e ocena u¿ytkownika $u$ dla przedmiotu $i$ bêdzie podobna
    do oceny innego u¿ytkownika $v$, którego dotychczasowy schemat oceniania by³
    zbli¿ony do ocen $u$.
    Analogicznie, preferencje u¿ytkownika $u$ wobec przedmiotów $i$ oraz
    $j$ bêd± podobne, je¶li pozostali u¿ytkownicy oceniali oba przedmioty w
    analogiczny sposób.
    
    Algorytmy wspólnej filtracji mo¿na podzieliæ na dwa typy:
    \begin{itemize}
    \item wspólna filtracja oparta na modelu - systemy oparte na tym podej¶ciu
    wykorzystuj± dostêpne oceny w celu wyuczenia modelu, który nastêpnie
    bêdzie przewidywa³ nieznane warto¶ci $r_{ui}$. W tego typu metodzie u¿ywa siê
    na przyk³ad rozk³adu macierzy u¿yteczno¶ci wed³ug warto¶ci osobliwych,
    maszyn wektorów wspieraj±cych, sieci Bayesowskich oraz
    algorytmu Expectation - Maximisation.
    \item wspólna filtracja oparta na s±siedztwie - w tej metodzie ustala siê
    funkcjê podobieñstwa, a nastêpnie u¿ywa siê jej do wyznaczenia zbioru \textit{s±siadów} -
    u¿ytkowników b±d¼ przedmiotów charakteryzuj±cych siê podobnym schematem oceniania.
    Ostateczna ocena wyznaczana jest tylko na podstawie ocen s±siadów.
    \end{itemize}
        
    Szczegó³ow± analizê filtracji opartej na modelu mo¿na znale¼æ w \cite{ricci}. W dalszej czê¶ci pracy
    autor skupi siê na podej¶ciu bazuj±cym na s±siedztwie.
    
    
\section{Filtracja w oparciu o u¿ytkowników}
    Podej¶cie bazuj±ce na u¿ytkownikach by³o pierwsz± zautomatyzowan±
    metod± wspólnej filtracji. Zosta³o wprowadzone pierwszy raz w ramach
   \textit{GroupLens Research Project}\footnote{Projekt badawczy prowadzony na Uniwersytecie Minnesota} (¼ród³o: \cite{ekstr}).
    
    Za³ó¿my, ¿e dana jest funkcja podobieñstwa $s_{users}: U \times U \rightarrow \mathbb{R}$.
    Schemat wyznaczania oceny u¿ytkownika $u$ dla przedmiotu $i$
    jest nastêpuj±cy:
    \begin{algorithm}[ht]\label{alg}
    \LinesNumbered{
    \ForEach{$u' \in U \setminus \{u\}$}{
        Oblicz $s_{users}(u, u')$\;
    }        
    Na podstawie warto¶ci $s_{users}$, wyznacz $N_i(u)$ - zbiór s±siadów, którzy ocenili $i$\; \label{alg:select}
    Wyznacz predykcjê oceny $\hat{r}_{ui}$ na podstawie $\{r_{vi} \; | \; v \in N_i(u)\}$\; \label{alg:result}
    }
    \end{algorithm}
    
    Najczê¶ciej spotykan± metod± wyznaczania zbioru s±siadów $N_i(u)$
    (linia \ref{alg:select})
    jest wybranie $k$ u¿ytkowników o najwiêkszej warto¶ci funkcji podobieñstwa,
    gdzie $k$ jest parametrem algorytmu. Podstawow± metod± wyznaczania predykcji
    (linia \ref{alg:result}) jest z kolei wziêcie ¶redniej oceny ze zbioru s±siadów:
     \begin{equation} \label{result:mean}
        \hat{r}_{ui} = \frac{1}{|N_i(u)|} \sum_{v \in N_i(u)} r_{vi}
    \end{equation}

\subsection{Wyznaczanie podobieñstwa miêdzy u¿ytkownikami} \label{subs:user_sim}

    Wybór odpowiedniej funkcji podobieñstwa $s_{users}$ jest najwa¿niejsz± czê¶ci± algorytmu
    wspólnej filtracji. Odgrywa ona podwójn± rolê:
    \begin{itemize}
    \item umo¿liwia wyznaczenie odpowiedniego zbioru $N_i(u)$
    \item w niektórych podej¶ciach warto¶ci funkcji $s_{users}$ pozwalaj± na dok³adniejsze
    wyznaczenie ostatecznego wyniku (wiêcej w rozdziale \ref{r:optimization})
    \end{itemize}
    Poni¿ej znajduje siê przegl±d funkcji podobieñstwa najczê¶ciej opisywanych w literaturze.
    
\subsubsection{Miary podobieñstwa bazuj±ce na korelacji}
    \begin{itemize}
    \item \textbf{Wspó³czynnik korelacji liniowej Pearsona}
    
    Wspó³czynnik Pearsona okre¶la poziom zale¿no¶ci liniowej miêdzy zmiennymi losowymi.
    Estymator wspó³czynnika korelacji liniowej dla wektorów prób losowych
    $x, y \in \mathbb{R}^n$ jest zdefiniowany nastêpuj±co:
    \begin{equation}
         pearson_{xy} = \frac{\sum_{i=1}^n(x_i - \mean{x})(y_i - \mean{y})}{\sqrt{\sum_{i=1}^n (x_i - \mean{x})^2}\sqrt{\sum_{i=1}^n (y_i - \mean{y})^2}},
    \end{equation}
    gdzie $\mean{x}$, $\mean{y}$ oznaczaj± warto¶ci ¶rednie z tych prób, tj
    $\mean{x} = \frac{\sum_{i=1}^n x_i}{n}$, $\mean{y} = \frac{\sum_{i=1}^n y_i}{n}$.
    Wspó³czynnik korelacji Pearsona przyjmuje warto¶ci z przedzia³u $[-1,1]$. Warto¶ci
    bliskie $1$ oznaczaj± siln± zale¿no¶æ liniow± miêdzy $x$ a $y$, warto¶ci bliskie zera - 
    brak liniowej zale¿no¶ci, natomiast warto¶ci bliskie $-1$ - ujemn± liniow± zale¿no¶æ.
    
    W kontek¶cie systemów rekomendacyjnych, wspó³czynnik korelacji okre¶la siê jak poni¿ej:
    \begin{equation}
        pearson\_corr(u, v) = \frac{\sum_{i \in I_u \cap I_v}(r_{ui} - \mean{r}_u)(r_{vi} - \mean{r}_v)}{\sqrt{\sum_{i \in I_u \cap I_v}(r_{ui} - \mean{r}_u)^2}\sqrt{\sum_{i \in I_u \cap I_v}(r_{vi} - \mean{r}_v)^2}}, \label{sim:pearson}
    \end{equation}
    gdzie $I_u$, $I_v$ reprezentuj± zbiory przedmiotów ocenionych (odpowiednio) przez
    u¿ytkowników $u$ i $v$.
    
    Jest to najbardziej popularna funkcja do okre¶lania podobieñstwa miêdzy u¿ytkownikami.
    Wad± korelacji Pearsona jest zwracanie wysokiego podobieñstwa dla par u¿ytkowników,
    którzy ocenili niewielk± liczbê takich samych przedmiotów. Jednym z mo¿liwych
    sposobów obej¶cia tego problemu jest ustalenie progu $T$ rozmiaru
    zbioru $I_u \cap I_v$ i przeskalowanie
    wyniku, przyk³adowo przez pomno¿enie go przez $min(\frac{|I_u \cap I_v|}{T}, 1)$ (\cite{ekstr}).
    
    \item \textbf{Zmodyfikowana korelacja Pearsona}
    
    Niektóre systemy interpretuj± warto¶æ $r_{med}$ (mediany uporz±dkowanego zbioru
    ocen $R$) jako neutralne nastawienie
    u¿ytkownika wobec przedmiotu. Ekstrand i in. zaproponowali w \cite{ekstr}
    modyfikacjê wspó³czynnika korelacji Pearsona, w której wektor ocen jest normalizowany
    przy u¿yciu owej mediany zamiast ¶redniej:
    \begin{equation}
        median\_centered\_corr(u, v) = \frac{\sum_{i \in I_u \cap I_v}(r_{ui} - r_{med})(r_{vi} - r_{med})}{\sqrt{\sum_{i \in I_u \cap I_v}(r_{ui} - r_{med})^2}\sqrt{\sum_{i \in I_u \cap I_v}(r_{vi} - r_{med})^2}}
    \end{equation}
   
    \item \textbf{Wspó³czynnik korelacji rang Spearmana}
    
    Podczas gdy wspó³czynnik Pearsona wykorzystuje bezpo¶rednie warto¶ci
    ocen $r_{ui}$ do wyznaczenia korelacji, metoda Spearmana polega na przyznaniu
    tym ocenom rang. Wektor ocen $r_u$ jest przekszta³cany w wektor rang w nastêpuj±cy
    sposób: najwy¿ej oceniony przedmiot otrzymuje rangê $1$, kolejne przedmioty
    otrzymuj± wy¿sze rangi. Przedmiotom z t± sam± ocen± przyznaje siê ¶redni± rangê
    dla ich pozycji. Oznaczaj±c przez $k_{ui}$ rangê przyznan± przedmiotowi $i$
    w kontek¶cie u¿ytkownika $u$, otrzymujemy wzór:
    \begin{equation}
        spearman\_rank\_corr(u, v) = \frac{\sum_{i \in I_u \cap I_v}(k_{ui} - \mean{k}_u)(k_{vi} - \mean{k}_v)}{\sqrt{\sum_{i \in I_u \cap I_v}(k_{ui} - \mean{k}_u)^2}\sqrt{\sum_{i \in I_u \cap I_v}(k_{vi} - \mean{k}_v)^2}}
    \end{equation}
        
    G³ówn± zalet± wspó³czynnika Spearmana jest unikniêcie problemu normalizacji
    ocen (wiêcej o normalizacji w rozdziale \ref{r:optimization}). Obliczanie rang wymaga
    jednak dodatkowego kosztu.
    \end{itemize}
    
\subsubsection{Inne miary podobieñstwa}
    \begin{itemize}
    \item \textbf{Podobieñstwo cosinusowe}
    
    Cosinus k±ta miêdzy wektorami $x$, $y$ w przestrzeni euklidesowej $(V, < \cdot >)$
    wyra¿a siê przez:
    \begin{equation}
        cos(x, y) = \frac{<x, y>}{\norm{x} \norm{y}}
    \end{equation}
    Dla wektorów z przestrzeni $\mathbb{R}^n$ ze standardowym iloczynem skalarnym,
    im wiêksza warto¶æ bezwzglêdna cosinusa, tym mniejszy k±t miêdzy nimi,
    co z kolei odpowiada intuicyjnie wiêkszemu "podobieñstwu" miêdzy wektorami.
    
    Ta intuicja le¿y u podstaw wykorzystania miary cosinusowe jako funkcji podobieñstwa,
    definuj±c j± jak poni¿ej:
    \begin{equation}
        cosine(u, v) = \frac{r_u \cdot r_v}{\norm{r_u}_2 \norm{r_v}_2} \label{sim:cosine}
    \end{equation}
    
    Wad± wydawaæ siê mo¿e reprezentowanie nieznanych ocen przez $0$, co czêsto
    upodabnia brak oceny do oceny negatywnej. Co wiêcej, u¿ywanie tej funkcji
    podobieñstwa nie bierze pod uwagê statystycznych ró¿nic miêdzy ocenami u¿ytkowników
    (ró¿nych ¶rednich czy wariancji ocen).
    Mimo wymienionych wad, podobieñstwo cosinusowe daje zaskakuj±co dobre wyniki w praktyce.
    
    \item \textbf{Podobieñstwo Jaccarda}
    
    Wspó³czynnik podobieñstwa Jaccarda (inaczej: \textit{indeks Jaccarda}) mierzy podobieñstwo miêdzy dwoma zbiorami i jest zdefiniowany jako iloraz mocy przeciêcia
    zbiorów i mocy sum tych zbiorów. W kontek¶cie systemów rekomendacji
    wylicza siê go zatem nastêpuj±co:
    \begin{equation}
        jaccard(u, v) = \frac{|I_u \cap I_v|}{|I_u \cup I_v|} \label{sim:jaccard}
    \end{equation}
    Jako ¿e indeks Jaccarda ignoruje warto¶ci ocen, jego oczywist± wad± jest fakt utraty
    informacji przy skalach ocen innych unarna.
        
    \item \textbf{Rozszerzone podobieñstwo Jaccarda}
    
    Jest to wersja podobieñstwa Jaccarda dla wektorów z $\mathbb{R}^n$:
    \begin{equation}
        extended\_jaccard(x, y) = \frac{x \cdot y}{\norm{x}_2^2 + \norm{y}_2^2 - x \cdot y},
    \end{equation}
    czyli u¿ywane jako miara podobieñstwa u¿ytkowników bêdzie mia³o postaæ:
    \begin{equation}
        extended\_jaccard(u, v) = \frac{r_u \cdot r_v}{\norm{r_u}_2^2 + \norm{r_v}_2^2 - r_u \cdot r_v}, \label{sim:ext_jaccard}
    \end{equation}
    
    \item \textbf{Podobieñstwo euklidesowe}
    
    Odleg³o¶æ euklidesowa miêdzy
    u¿ytkownikami okre¶lona jest w naturalny sposób przez:
    \begin{equation}
       d_2(u, v) = \sqrt{\sum_{i \in I_u \cap I_v} (r_{ui} - r_{vi})^2}.
    \end{equation}
    S± ró¿ne mo¿liwo¶ci przekszta³cenia tej miary odleg³o¶ci w funkcjê podobieñstwa
    (id±c± w $[0, 1]$, gdzie 1 oznacza najwiêksze podobieñstwo).
    Do najczê¶ciej u¿ywanych nale¿±:
    \begin{equation}
       euclidean1(u, v) = \frac{1}{1 + d_2(u, v)} \label{sim:euclidean1}
    \end{equation}
    oraz
    \begin{equation}
       euclidean2(u, v) = e^{-d_2(u, v)} \label{sim:euclidean2}
    \end{equation}
    Te miary mo¿e byæ uogólniona poprzez u¿ycie odleg³o¶ci Minkowskiego:
    \begin{equation}
       d_p(u, v) = \bigg(\sum_{i \in I_u \cap I_v} |r_{ui} - r_{vi}|^p \bigg)^{\frac{1}{p}}
    \end{equation}   
     
    \item \textbf{Ró¿nica ¶redniokwadratowa (ang. \textit{mean squared difference, MSD})}
    
    Podobn±, bazuj±c± na odleg³o¶ci miêdzy ocenami funkcj± podobieñstwa jest ró¿nica
    ¶redniokwadratowa. Definiuje siê j± jako odwrotno¶æ ¶redniego kwadratu ró¿nicy
    miêdzy ocenami u¿ytkowników $u$ i $v$:
    \begin{equation}
        MSD(u, v) = \frac{|I_u \cap I_v |}{\sum_{i \in I_u \cap I_v} (r_{ui} - r_{vi})^2}
    \end{equation}
    
    Ró¿nica ¶redniokwadratowa, podobnie jak podobieñstwo euklidesowe,
    nie odzwierciedla ujemnej korelacji miêdzy u¿ytkownikami. Posiadanie informacji
    o takiej korelacji mo¿e czasami zwiêkszyæ jako¶æ predykcji (\cite{ricci}).
    \end{itemize}

\section{Filtracja w oparciu o przedmioty}
    Obok wielu zalet, wspólna filtracja bazuj±ca na u¿ytkownikach ma jedn± powa¿n±
    wadê - brak skalowalno¶ci. Wyznaczanie zbioru $N_i(u)$ jest operacj± o z³o¿ono¶ci
    $\mathcal{O}(|U|)$ (lub gorszej - bezpo¶rednie wyliczanie warto¶ci funkcji podobieñstwa
    $s$ wymaga czasu $\mathcal{O}(|U||I|)$). W dobie serwisów maj±cych setki milionów
    u¿ytkowników potrzebne by³o bardziej skalowalne podej¶cie.
    
    Naturalnym pomys³em wydawa³o siê zastosowanie tej samej metody,
    zmodyfikowanej przez zast±pienie u¿ytkowników przedmiotami. Zamiast szukania
    podobieñstw miêdzy zachowaniami u¿ytkowników, do wyznaczania rekomendacji
    wykorzystywane s± podobieñstwa miêdzy schematami oceniania przedmiotów.
    Je¶li dwa przedmioty $i$ i $j$ cieszy³y siê podobn± opini± w¶ród
    u¿ytkowników, mo¿na uznaæ je za podobne i wykorzystaæ ocenê, jak± u¿ytkownik $u$
    wystawi³ przedmiotowi $i$ do predykcji oceny dla przedmiotu $j$.
    Warto zauwa¿yæ, ¿e ta wersja metody \textit{collaborative filtering} jest podobna
    do rekomendacji opartej na zawarto¶ci, z t± ró¿nic±, ¿e
    do wyznaczania podobieñstwa u¿ywa siê preferencji u¿ytkowników zamiast cech
    przedmiotów.
    
    Zamiast funkcji $s_{users}$ mamy zatem funkcjê
    $s_{items}: I \times I \rightarrow \mathbb{R}$, na której podstawie
    wyznaczamy zbiór $N_u(i)$ przedmiotów najbardziej podobnych do $i$
    ocenionych przez $u$. Porównanie z³o¿ono¶ci czasowej i obliczeniowej obu
    sposobów wspólnej filtracji przedstawia tabela \ref{t:complexities}.
\hfill \\  
\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Porównanie z³o¿ono¶ci pamiêciowej i obliczeniowej obu \\wersji wspólnej filtracji} \label{t:complexities}
\begin{tabular}{|l|l|l|l|}
\hline
            & Pamiêæ               & Czas uczenia            & Czas zapytania     \\ \hline
U¿ytkownicy & $\mathcal{O}(|U|^2)$ & $\mathcal{O}(|U|^2|I|)$ & $\mathcal{O}(|U|)$ \\ \hline
Przedmioty  & $\mathcal{O}(|I|^2)$ & $\mathcal{O}(|I|^2|U|)$ & $\mathcal{O}(|I|)$ \\ \hline
\end{tabular}
\end{table}

\hfill \\
Zak³adaj±c, ¿e $|U| \gg |I|$ (co jest prawd± w przypadku wiêkszo¶ci serwisów), ³atwo
zauwa¿yæ, ¿e "przedmiotowe" podej¶cie do wspólnej filtracji pozwala w znacz±cy sposób
zmniejszyæ z³o¿ono¶æ zarówno czasow±, jak i pamiêciow± algorytmu. Warto przy tym
zaznaczyæ, ¿e macierz u¿yteczno¶ci jest czêsto macierz± rzadk±, co znacznie przyspiesza
obliczanie warto¶ci funkcji podobieñstwa i  czyni metodê wspólnej filtracji
opart± na s±siedztwie jeszcze lepiej skalowaln±.

\subsection{Wyznaczanie podobieñstwa miêdzy przedmiotami} \label{subs:item_sim}

Nietrudno zauwa¿yæ, ¿e wymienione w sekcji \ref{subs:user_sim} funkcje podobieñstwa
mog± byæ z powodzeniem uogólnione i zastosowane przy wyznaczaniu podobieñstwa miêdzy
przedmiotami. Przyk³adowo, wspó³czynnik korelacji liniowej Pearsona (równanie \ref{sim:pearson}) dla przedmiotów mo¿na
zdefiniowaæ jako:
\begin{equation}
  pearson\_corr(i, j) = \frac{\sum_{u \in U_i \cap U_j}(r_{ui} - \mean{c}_i)(r_{uj} - \mean{c}_j)}{\sqrt{\sum_{u \in U_i \cap U_j}(r_{ui} - \mean{c}_i)^2}\sqrt{\sum_{u \in U_i \cap U_v}(r_{uj} - \mean{c}_j)^2}}
\end{equation}
Analogicznie zdefiniowaæ mo¿na pozosta³e miary.

Miarê podobieñstwa przeznaczon± specjalnie dla przedmiotów
zaproponowali Sarwar i in. w \cite{sarwar}. Bazuje ona na obserwacji,
i¿ ró¿nice w skalach ocen poszczególnych u¿ytkowników czêsto s± znacznie
wyra¼niejsze ni¿ w przypadku przedmiotów. Dlatego przy obliczaniu podobieñstwa
miêdzy przedmiotami wiêkszy sens mo¿e mieæ normalizacja oceny wzglêdem ¶redniej
oceny \textit{u¿ytkownika} zamiast \textit{przedmiotu}. Formalnie ta miara, zwana
\textbf{dopasowanym podobieñstwem cosinusowym (ang. \textit{Adjusted Cosine Similarity})} okre¶lona jest jako:
\begin{equation}
adjusted\_cosine(i, j) = \frac{\sum_{u \in U_i \cap U_j}(r_{ui} - \mean{r}_u)(r_{uj} - \mean{r}_u)}{\sqrt{\sum_{u \in U_i \cap U_j}(r_{ui} - \mean{r}_u)^2}\sqrt{\sum_{u \in U_i \cap U_v}(r_{uj} - \mean{r}_u)^2}} \label{sim:adjusted_cos}
\end{equation}

W niektórych przypadkach tak okre¶lona funkcja podobieñstwa daje lepsze wyniki ni¿
zwykle u¿ywane miary.

\afterpage{\blankpage}

\chapter{Wp³yw miary podobieñstwa na jako¶æ predykcji} \label{r:experiment}

W poni¿szym rozdziale przedstawione zostan± wyniki eksperymentu, maj±cego na celu
ukazanie, jak wybór metody wspólnej filtracji oraz funkcji podobieñstwa wp³ywa
na jako¶æ systemu rekomendacji.

\section{Opis eksperymentu} \label{s:experiment}
\subsection{Opis zbioru danych}

W pracy wykorzystany zosta³ zbiór ocen filmów MovieLens\footnote{https://movielens.org/}. Zbiór sk³ada siê ze 100,000 ocen udzielonych 1682 filmom przez 943
u¿ytkowników, przy czym ka¿dy u¿ytkownik oceni³ co najmniej 20 filmów.
Skala ocen jest piêciopunktowa. Obok samych ocen, zbiór zawiera³ podstawowe informacje na temat filmów (m.in. tytu³, gatunek, datê wydania) oraz u¿ytkowników (wiek, p³eæ, zawód,
kod pocztowy). Dane zbierane
by³y w ramach wspomnianego wcze¶niej projektu GroupLens przez 7 miesiêcy.

\subsection{Sposób przeprowadzenia eksperymentu}

Jako¶æ predykcji sprawdzana by³a przy u¿yciu piêciowarstwowej walidacji krzy¿owej.
Zbiór ocen by³ podzielony na 5 równolicznych, roz³±cznych podzbiorów - skorzystano 
z gotowego podzia³u dostarczonego razem ze zbiorem danych przez zespó³ GroupLens.
Nastêpnie kolejno ka¿dy z podzbiorów s³u¿y³ jako zbiór testowy, a cztery pozosta³e
podzbiory tworzy³y zbiór treningowy. Ostateczny wynik jest ¶redni± z wyników piêciu
przeprowadzonych analiz.

Do oceny jako¶ci predykcji u¿yto funkcji straty opisanych w rozdziale \ref{r:definitions} -
MAE oraz RMSE.

Zbiór s±siadów wyznaczany by³ przez wziêcie 10 najbardziej podobnych u¿ytkowników b±d¼
przedmiotów. Ostateczna ocena wyliczana by³a jako ¶rednia z ocen s±siadów (zgodnie ze wzorem \ref{result:mean}).

Aby uzyskaæ punkt odniesienia, dla obydwu podej¶æ zosta³ równie¿ dodany wynik
predyktora bazowego (\textit{baseline}) - w przypadku u¿ytkowników zwraca³ on ¶redni±
ocenê dla danego u¿ytkownika ($\hat{r}_{ui} = \mean{r}_u$), a w przypadku przedmiotów -
¶redni± ocenê wystawion± przedmiotowi ($\hat{r}_{ui} = \mean{c}_i$).

\section{Wyniki}
Wyniki dla metody bazuj±cej na u¿ytkownikach w zale¿no¶ci od postaci funkcji podobieñstwa $s_{users}$ prezentuje tabela
\ref{t:exp_users}.

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Wyniki dla podej¶cia opartego na u¿ytkownikach}
\label{t:exp_users}
\begin{tabular}{|c|c|c|}
\hline
                         & MAE & RMSE \\ \hline
\textbf{$baseline$}      & \textbf{0.828} & \textbf{1.031} \\ \hline
$pearson\_corr$          & 0.817   & 1.028    \\ \hline
$median\_centered\_corr$ & 0.800   & 1.016    \\ \hline
$spearman\_rank\_corr$   & 0.825   & 1.039    \\ \hline
$cosine$                 & 0.818   & 1.029    \\ \hline
$jaccard$                &  0.823   &  1.037    \\ \hline
$extended\_jaccard$      & 0.818    & 1.026     \\ \hline
$euclidean1$             &  0.865   &  1.069    \\ \hline
$euclidean2$             &  0.865   &  1.069    \\ \hline
$MSD$                    &   \textbf{0.787}  &  \textbf{0.998}    \\ \hline
\end{tabular}
\end{table}

\hfill \\
Wyniki dla metody bazuj±cej na przedmiotach w zale¿no¶ci od postaci funkcji podobieñstwa $s_{items}$ prezentuje tabela
\ref{t:exp_items}.

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Wyniki dla podej¶cia opartego na przedmiotach}
\label{t:exp_items}
\begin{tabular}{|c|c|c|}
\hline
                         & MAE & RMSE \\ \hline
\textbf{$baseline$}      & \textbf{0.803} & \textbf{1.000} \\ \hline
$pearson\_corr$          & 0.749   & 0.959    \\ \hline
$median\_centered\_corr$ & 0.779   & 0.998    \\ \hline
$spearman\_rank\_corr$   & 0.764   &  0.976   \\ \hline
$cosine$                 & 0.763   & 0.981    \\ \hline
$jaccard$                & 0.753    & 0.966     \\ \hline
$extended\_jaccard$      &  \textbf{0.742}   & \textbf{0.953}     \\ \hline
$euclidean1$             &  0.885   &  1.104    \\ \hline
$euclidean2$             &  0.885   &  1.104    \\ \hline
$MSD$                    &  0.809  & 1.030     \\ \hline
$adjusted\_cosine$       & 0.792    & 1.007     \\ \hline
\end{tabular}
\end{table}

\hfill \\
W obu tabelach wyró¿niono wynik predyktora bazowego oraz najlepszy uzyskany wynik.

\section{Wnioski}

Mimo braku optymalizacji parametru $k$ oraz mimo naiwnej metody wyznaczania
oceny na podstawie ocen s±siadów, odpowiedni wybór funkcji podobieñstwa poprawia
wynik predyktora bazowego o oko³o 5\%. Interesuj±cy wydaje siê fakt, i¿ najlepsze
wynik uzyskano przy u¿yciu miar podobieñstwa raczej rzadko spotykanych w literaturze -
w przypadku u¿ytkowników by³a to miara $MSD$, a w przypadku przedmiotów -
$extended\_jaccard$. Miara wymieniana najczê¶ciej - wspó³czynnik korelacji Pearsona -
da³a z kolei stosunkowo nisk± jako¶æ predykcji w podej¶ciu
bazuj±cym na u¿ytkownikach.
Do¶æ zaskakuj±ce s± te¿ rezultaty otrzymane przy wykorzystaniu
miar opartych na odleg³o¶ci euklidesowej - $euclidean1$ i $euclidean2$. Obie da³y identyczne
wyniki, co znaczy, ¿e bardzo czêsto zwraca³y ten sam zbiór s±siadów. Co ciekawe,
jako¶æ predykcji uzyskana przy u¿yciu tych miar by³a w obu przypadkach najgorsza.
Interesuj±cy jest równie¿ wysoki wynik otrzymany w podej¶ciu opartym na przedmiotach
przy u¿yciu podobieñstwa Jaccarda - w teorii miara ta wydaje siê najmniej u¿yteczna
ze wszystkich funkcji podobieñstwa opisanych w rozdziale \ref{r:filtracja}.

\chapter{Optymalizacja algorytmu opartego na s±siedztwie}\label{r:optimization}

W poni¿szym rozdziale przeanalizowane zostan± szczegó³y algorytmu najbli¿szych s±siadów - 
wybór zbioru s±siadów oraz wyliczanie wyniku na ich podstawie. Zaprezentowane zostan±
wyniki dalszych eksperymentów pokazuj±cych, jak obydwa aspekty wp³ywaj± na jako¶æ
predykcji.

\section{Wyznaczanie zbioru s±siadów} \label{s:neighbours}
Rozmiar zbioru $N$ najbli¿szych s±siadów oraz sposób tworzenia tego zbioru
na podstawie funkcji podobieñstwa mog± mieæ znaczny wp³yw na jako¶æ
systemu rekomendacji. Przyk³adowo, pierwszy system rekomendacji
GropuLens przyjmowa³ $N_i(u) = U \setminus \{u\}$ - jednak branie pod uwagê
u¿ytkowników o niskiej korelacji zmniejsza³o jako¶æ predykcji (\cite{ekstr}).

Naturalne wydaje siê wiêc wybieranie s±siadów na podstawie warto¶ci funkcji podobieñstwa.
Przy wiêkszej liczbie u¿ytkowników niemo¿liwe staje siê jednak
trzymanie ca³ej macierzy podobieñstwa w pamiêci. Równie¿ z powodu zbyt wysokiej 
z³o¿ono¶ci czasowej przegl±danie ca³ego zbioru $U$ lub $I$ przy ka¿dym zapytaniu
by³oby nieakcpetowalne. Z tego powodu wyznaczanie zbioru $N$
jest czêsto podzielone na dwa etapy: etap preprocessingu, w którym dla ka¿dego u¿ytkownika b±d¼ przedmiotu wylicza siê zbiór kandydatów na s±siadów, oraz etap
w³a¶ciwego wyboru s±siedztwa.

\subsection{Etap preprocessingu}

W tym etapie dla ka¿dego u¿ytkownika $u$ lub przedmiotu $i$ wyznaczany jest podzbiór
$U' \subset U$ (odpowiednio: $I' \subset I|$), przy czym $|U'| \ll |U|$, który, trzymany
w pamiêci podrêcznej, bêdzie pó¼niej s³u¿y³ do wyznaczania zbioru s±siadów. Warto przy tym tak dobraæ rozmiar zbioru $U'$, aby dla mo¿liwie du¿ej liczby zapytañ o ocenê $r_{uj}$
rozmiar zbioru $U' \setminus U_j$ przekracza³ oczekiwany rozmiar $N$.
Do najbardziej popularnych metod preprocessingu nale¿±:
\begin{itemize}
\item wybór $k'$ s±siadów z najwiêksz± warto¶ci± funkcji podobieñstwa
\item wybór s±siadów, dla których warto¶æ funkcji podobieñstwa przekracza pewien
ustalony próg $T$
\item je¶li u¿ywana jest funkcja podobieñstwa bazuj±ca na korelacji (przyk³ady
takich funkcji opsiane by³y w sekcji \ref{subs:user_sim}), mo¿liwe jest odfiltrowanie s±siadów z ujemn± korelacj±
wzglêdem ocen danego u¿ytkownika b±d¼ przedmiotu.
\end{itemize}

\subsection{Wybór s±siedztwa}

Maj±c przygotowany zbiór $U'$ b±d¼ $I'$ kandydatów na s±siadów, mo¿na przyst±piæ
do w³a¶ciwego wyznaczenia zbioru $N$. Podobnie jak w etapie wstêpnego przetwarzania,
mo¿e to byæ wykonane dwojako:
\begin{itemize}
\item poprzez wybranie wszystkich s±siadów, dla których warto¶æ funkcji podobieñstwa
przekracza próg $T$, bêd±cy parametrem algorytmu - to podej¶cie zapewnia, ¿e
w zbiorze $N$ znajd± siê tylko "dostatecznie podobni" u¿ytkownicy b±d¼ "dostatecznie
podobne" przedmioty. Odpowiedni wybór warto¶ci progowej $T$ zale¿y jednak
od wybranej funkcji podobieñstwa i okre¶lenie jej mo¿e byæ nie³atwym zadaniem -
st±d rzadko stosuje siê tê metodê w praktyce.

\item poprzez wybranie $k$ "najbardziej podobnych" s±siadów, gdzie $k$ jest parametrem
algorytmu. 
\end{itemize}

Ze wzglêdu na swoj± prostotê i dobre wyniki w praktyce, wybór $k$ najbli¿szych s±siadów
jest najczê¶ciej stosowanym podej¶ciem we wspó³czesnych systemach rekomendacji.
Odpowiedni dobór parametru $k$ mo¿e wyra¼nie poprawiæ jako¶æ rekomendacji,
co najlepiej widaæ na wykresie \ref{w:k}. Przedstawia on zale¿no¶æ ¶redniego 
bezwzglêdnego b³êdu od warto¶ci $k$ dla obu
metod wspólnej filtracji przy wybranej funkcji podobieñstwa ($median\_centered\_corr$
dla u¿ytkowników oraz $adjusted\_cosine$ dla przedmiotów.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.8]{recommender.png}
\caption{Zale¿no¶æ MAE od parametru $k$ \label{w:k}}
\end{figure}

\hfill \\
Zwykle optymalna warto¶æ $k$ oscyluje miêdzy 10 a 50.

W \cite{ekstr} wspominana jest te¿ metoda, w której $k$ jest dobierane
dynamicznie w celu zmniejszenia b³êdu predykcji - ze wzglêdu na znaczne wyd³u¿enie
czasu zapytania nie jest ona jednak czêsto stosowana w praktyce.

\section{Wyznaczanie oceny na podstawie ocen s±siadów} \label{s:result_comp}

Ostatnim krokiem w algorytmie wspólnej filtracji jest ustalenie predykcji oceny $\hat{r}_{ui}$ na podstawie ocen s±siadów ze zbioru $N$. 
\subsection{¦rednia wa¿ona}
Podstawowe podej¶cie - wyliczenie ¶redniej arytmetycznej -
ma tê wadê, ¿e ignoruje warto¶ci funkcji podobieñstwa
dla s±siadów. Naturalnym pomys³em jest zatem zast±pienie ¶redniej arytmetycznej ¶redni± wa¿on± - dla u¿ytkowników:
\begin{equation} \label{result:w_mean_users}
    \hat{r}_{ui} = \frac{\sum_{v \in N_i(u)} s_{users}(u, v) r_{vi}}{\sum_{v \in N_i(u)} |s_{users}(u, v)|}
\end{equation}
oraz dla przedmiotów:
\begin{equation} \label{result:w_mean_items}
    \hat{r}_{ui} = \frac{\sum_{j \in N_u(i)} s_{items}(i, j) r_{uj}}{\sum_{j \in N_u(i)} |s_{items}(i, j)|}
\end{equation}

U¿ywanie ¶redniej wa¿onej jest najczê¶ciej stosowan± metod± wyliczania oceny (\cite{ricci,ekstr}).

\subsection{Normalizacja wzglêdem ¶redniej (ang. \textit{mean-centering})}
Jak wspominano we wcze¶niejszych rozdzia³ach, skala ocen u ró¿nych u¿ytkowników
mo¿e byæ odmienna (niektórzy u¿ytkownicy mog± mieæ tendencjê do dawania ni¿szych ocen, inni z kolei mog± oceniaæ wy³±cznie przedmioty, które im siê podoba³y).
Zamiast bezpo¶rednich ocen $r_{ui}$ proponuje siê wtedy wykorzystanie ocen $r'_{ui}$
znormalizowanych wzglêdem ¶redniej oceny danego u¿ytkownika: $r'_{ui} = r_{ui} - \mean{r}_u$. Intuicyjnie, znak
$r'_{ui}$ ma informowaæ o preferencji u¿ytkownika $u$ wobec
przedmiotu $i$ - czy jest on nastawiony do $i$ pozytywnie, czy negatywnie.
Wzór na $\hat{r}_{ui}$ przyjmuje wtedy postaæ:
\begin{equation} \label{result:w_mean_centered_users}
    \hat{r}_{ui} = \mean{r}_u + \frac{\sum_{v \in N_i(u)} s_{users}(u, v) (r_{vi} - \mean{r}_v)}{\sum_{v \in N_i(u)} |s_{users}(u, v)|}.
\end{equation}
Analogicznie, dla przedmiotów:
\begin{equation} \label{result:w_mean_centered_items}
    \hat{r}_{ui} = \mean{c}_i + \frac{\sum_{j \in N_u(i)} s_{items}(i, j)(r_{uj} - \mean{c}_j)}{\sum_{j \in N_u(i)} |s_{items}(i, j)|}
\end{equation}

\subsection{Standaryzacja Z (ang. \textit{z-score normalization})}
Powy¿sze podej¶cie mo¿e byæ dalej rozszerzone przez wziêcie pod uwagê odchylenia
ocen danego u¿ytkownika. Przyk³adowo, u¿ytkownicy $u_1$ i $u_2$ mog± mieæ ¶redni± ocen 3, przy czym $u_1$ wystawia³ wszystkie oceny z zakresu 1-5, a $u_2$ - tylko ocenê 3.
Wtedy ocena 5 wystawiona przez $u_2$ oznacza wiêksze zadowolenie z przedmiotu
ni¿ w przypadku u¿ytkownika $u_1$.

Dziel±c odchylenie $r_{ui}$ od ¶redniej
$\mean{r}_u$ przez odchylenie standardowe ocen danego u¿ytkownika $\sigma_u$,
dostajemy \textit{standaryzacjê Z} oceny $r_{ui}$:
\begin{equation}
z\_score(r_{ui}) = \frac{r_{ui} - \mean{r}_u}{\sigma_u}
\end{equation} 
W ten sposób niwelowany jest efekt ró¿nej rozpiêto¶ci ocen u u¿ytkowników. \\
Stosuj±c standaryzacjê Z, predykcjê $\hat{r}_{ui}$ otrzymuje siê przez
\begin{equation} \label{result:z_score_users}
    \hat{r}_{ui} = \mean{r}_u + \sigma_u\frac{\sum_{v \in N_i(u)} s_{users}(u, v) \frac{r_{vi} - \mean{r}_v}{\sigma_v}}{\sum_{v \in N_i(u)} |s_{users}(u, v)|}.
\end{equation}
dla u¿ytkowników oraz
\begin{equation} \label{result:z_score_items}
    \hat{r}_{ui} = \mean{c}_i + \sigma_i\frac{\sum_{j \in N_u(i)} s_{items}(i, j)\frac{r_{uj} - \mean{c}_j}{\sigma_j}}{\sum_{j \in N_u(i)} |s_{items}(i, j)|}
\end{equation}
dla przedmiotów.

\subsection{Eksperymenty i wnioski}

Tabele \ref{t:res1} i \ref{t:res2} przedstawiaj± wyniki otrzymane przy zastosowaniu
opisanych metod. Parametry algorytmu - liczba s±siadów $k$ oraz funkcja podobieñstwa - zosta³y dobrane tak, aby otrzymaæ jak najlepsz± jako¶æ predykcji. Ostatecznie
w obu przypadkach
u¿yto wspó³czynnika korelacji Pearsona jako miary podobieñstwa i warto¶ci $k$ równej 20.
\hfill \\
\begin{table}[ht]
\begin{minipage}{0.5\textwidth}
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Wyniki dla podej¶cia opartego na u¿ytkownikach przy $k = 20$ i $s_{users} = pearson\_corr$}
\label{t:res1}
\begin{tabular}{|c|c|c|}
\hline
                         & MAE & RMSE \\ \hline
¶rednia wa¿ona          & 0.807   & 1.016    \\ \hline
$mean-centering$ & 0.741   & 0.947    \\ \hline
$z-score$   & 0.738   &  0.946   \\ \hline
\end{tabular}
\end{minipage}
\hfillx
\begin{minipage}{0.5\textwidth}
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Wyniki dla podej¶cia opartego na przedmiotach przy $k = 20$ i $s_{items} = pearson\_corr$}
\label{t:res2}
\begin{tabular}{|c|c|c|}
\hline
                         & MAE & RMSE \\ \hline
¶rednia wa¿ona          & 0.758   & 0.972    \\ \hline
$mean-centering$ & 0.715   & 0.912    \\ \hline
$z-score$   & 0.717   &  0.916   \\ \hline
\end{tabular}
\end{minipage}
\end{table}

\hfill \\
Jak widaæ, zastosowanie obu typów normalizacji (wzglêdem ¶redniej oraz standaryzacji Z)
znacznie poprawi³o jako¶æ predykcji - przyk³adowo, u¿ycie $mean-centering$ w podej¶ciu opartym na przedmiotach obni¿y³o ¶redni bezwzglêdny b³±d o ponad 10\% w stosunku do predyktora bazowego opisanego w
rozdziale \ref{r:experiment} (z 0.803 do 0.715). Nie widaæ natomiast wyra¼nej ró¿nicy miêdzy
tymi dwoma sposobami normalizacji. Zaskakuj± stosunkowo s³abe wyniki otrzymane przy u¿yciu ¶redniej wa¿onej - u¿ycie jej poprawi³o wynik tylko nieznacznie (w przypadku u¿ytkowników)
lub nawet go pogorszy³o (w przypadku przedmiotów) w stosunku do podej¶cia stosuj±cego zwyk³± ¶redni± arytmetyczn±.

\afterpage{\blankpage}

\chapter{Podsumowanie}
W pracy dokonano szczegó³owej analizy metody wspólnej filtracji opartej
na algorytmie najbli¿szych s±siadów.
Na wstêpie przedstawiono ró¿ne typy systemów rekomendacyjnych oraz idêê
stoj±c± za wspóln± filtracj±.
Opisano dwa podej¶cia do \textit{collaborative filtering} -
bazuj±ce na u¿ytkownikach oraz bazuj±ce na przedmiotach.
Przedstawiono te¿ obszerny spis funkcji podobieñstwa u¿ywanych w algorytmie
najbli¿szych s±siadów.

Zasadniczym celem autora by³o jednak pokazanie, ¿e nawet przy tak nieskomplikowanym
algorytmie, jakim bez w±tpienia jest algorytm najbli¿szych s±siadów, mo¿liwe
jest znaczne poprawienie wyników predykcji poprzez dog³êbn± analizê kolejnych
kroków algorytmu. W kolejnych rozdzia³ach przeanalizowano:
\begin{enumerate}
\item wybór odpowiedniej funkcji podobieñstwa (rozdzia³ \ref{r:experiment}),
\item strategie konstruowania zbioru s±siadów (sekcja \ref{s:neighbours}),
\item metody wyznaczania ostatecznej predykcji na podstawie ocen s±siadów (sekcja \ref{s:result_comp}).
\end{enumerate}
Dziêki kolejnym modyfikacjom algorytmu uda³o siê ostatecznie poprawiæ jako¶æ predykcji o ponad 10\% w stosunku do modelu bazowego. Warto zaznaczyæ, ¿e mimo dokonanych
zmian, zachowane zosta³y dwie zalety algorytmu, które zadecydowa³y o jego popularno¶ci
- prostota implementacji i skalowalno¶æ.

\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}

\bibitem[Ricci10]{ricci} Francesco Ricci, Lior Rokach, Bracha Shapira, Paul B. Kantor,
\textit{Recommender Systems Handbook}, Springer, 2010

\bibitem[Raj13]{rajaraman} Anand Rajaraman, Jure Leskovec, Jeffrey D. Ullman, \textit{Mining of Massive Datasets}, 2013

\bibitem[Ekstrand10]{ekstr} Michael D. Ekstrand, John T. Riedl, Joseph A. Konstan,
\textit{Collaborative Filtering Recommender Systems}, Foundations and Trends in
Human - Computer Interaction, Vol. 4, No. 2 (2010), s. 81 - 173

\bibitem[Sarwar01]{sarwar} Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl,
\textit{Item-Based Collaborative Filtering Recommendation Algorithms}, University of Minnesota, Minneapolis 2001

\bibitem[Ge11]{ge} Xinyang Ge, Jia Liu, Qi Qi, Zhenyu Chen,
\textit{A New Prediction Approach Based on Linear
Regression for Collaborative Filtering}, Nanjing University, 2011

\bibitem[Koren09]{koren} Y. Koren,
\textit{The BellKor Solution to the Netflix Grand Prize}, 2009

\bibitem[Celma07]{celma} O. Celma, P.Lamere,
\textit{ISMIR 2007 tutorial: music recommendation}

\bibitem[Buettner16]{buettner} R.Buettner,
\textit{Predicting user behavior in electronic markets based on personality-mining in large online social networks: A personality-based product recommender framework
}, Electronic Markets: The International Journal on Networked Business, s. 1 - 19



\end{thebibliography}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: latin-2
%%% End:
